{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ6wc2HE0pke"
      },
      "source": [
        "# **Experiment Notebook**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Align versions so pip stops warning\n",
        "!pip install -q --upgrade \"scikit-learn>=1.6\" \"umap-learn>=0.5.9\" utstd"
      ],
      "metadata": {
        "id": "2AIeLoxyVk37"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "!pip install -q utstd\n",
        "\n",
        "from utstd.ipyrenders import *"
      ],
      "metadata": {
        "id": "qNOA146K2c6f",
        "collapsed": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "metadata": {
        "id": "6FneOmBfka9G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Import Packages"
      ],
      "metadata": {
        "id": "mXFKfa2tp1ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys, json, math, pathlib, warnings, datetime\n",
        "from typing import List, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.base import BaseEstimator\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)"
      ],
      "metadata": {
        "id": "GBEAwdncnlAx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQgxLRrvjiJb"
      },
      "source": [
        "---\n",
        "## A. Project Description\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "student_name = \"Drashti Kakadiya\"\n",
        "student_id = \"25414741\"\n",
        "group_id = \"31\""
      ],
      "metadata": {
        "id": "Je1EzzfFD5hj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h1\", key='student_name', value=student_name)"
      ],
      "metadata": {
        "id": "pdKiYvFWD5my",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "a0389ab0-36e7-45ce-a4f2-87e82c6e07e3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">student_name</p><h1 font-size: 3em>Drashti Kakadiya</h1>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h1\", key='student_id', value=student_id)"
      ],
      "metadata": {
        "id": "9KTEbRjqD5o_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "dc186a1e-4fa5-4539-b862-9f65378ba5fd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">student_id</p><h1 font-size: 3em>25414741</h1>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h1\", key='group_id', value=group_id)"
      ],
      "metadata": {
        "id": "UKRt4jK6rInY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "2dcdfabb-4a17-4cf9-e713-70a8b0b40ae1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">group_id</p><h1 font-size: 3em>31</h1>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## B. Business Understanding"
      ],
      "metadata": {
        "id": "4q1Bzcejvfpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "business_use_case_description = \"\"\"\n",
        "Goal: predict each player’s draft probability so the team can prioritise scouting/offers and allocate budget efficiently.\n",
        "Impact: accurate → higher hit-rate, ROI, and wins; inaccurate → missed talent, wasted spend, weaker roster\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Mmo6apC9EEv8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='business_use_case_description', value=business_use_case_description)"
      ],
      "metadata": {
        "id": "bgb0DkG2EE2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "bba362fd-a262-40b4-888c-4a7816bf2279"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">business_use_case_description</p><h3 font-size: 3em>\n",
              "Goal: predict each player’s draft probability so the team can prioritise scouting/offers and allocate budget efficiently.\n",
              "Impact: accurate → higher hit-rate, ROI, and wins; inaccurate → missed talent, wasted spend, weaker roster\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "business_objectives = \"\"\"\n",
        "Identify and rank high-potential draftees to focus scouting/offers, boosting draft hit-rate and roster quality.\n",
        "Reduce wasted spend/time by filtering low-probability prospects, improving ROI and long-term team performance.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "29Yqk3d2EE8q"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='business_objectives', value=business_objectives)"
      ],
      "metadata": {
        "id": "sSu_8J96EFDs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "54a789f4-5444-459b-f5b1-492d14d7c5d9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">business_objectives</p><h3 font-size: 3em>\n",
              "Identify and rank high-potential draftees to focus scouting/offers, boosting draft hit-rate and roster quality.\n",
              "Reduce wasted spend/time by filtering low-probability prospects, improving ROI and long-term team performance.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "stakeholders_expectations_explanations = \"\"\"\n",
        "Owners/GM: Clear ROI (higher draft hit-rate, lower scouting cost), on-time insights before draft windows, and defensible KPIs (AUROC, calibration).\n",
        "Coaches: Short, trusted shortlists with thresholds and role-fit notes; minimal false positives that waste practice reps.\n",
        "Scouting Dept: Augmentation (not replacement) of scouts; transparent feature importance and a feedback loop to correct misses.\n",
        "Analytics/ML: Reproducible, leakage-free pipeline with versioned data, drift/quality monitoring, and easy what-if analyses.\n",
        "Compliance/Legal: Fairness checks across demographics, privacy-safe data handling, and auditable decisions.\n",
        "IT/Ops: Secure access, low-latency scoring API, uptime during peak draft activity, and smooth integration with existing tools.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Hf4ThY5cEF5W"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='stakeholders_expectations_explanations', value=stakeholders_expectations_explanations)"
      ],
      "metadata": {
        "id": "jH9a2X70EF8M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "143b7833-69c7-43bf-cfc0-ce5e0596ba54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">stakeholders_expectations_explanations</p><h3 font-size: 3em>\n",
              "Owners/GM: Clear ROI (higher draft hit-rate, lower scouting cost), on-time insights before draft windows, and defensible KPIs (AUROC, calibration).\n",
              "Coaches: Short, trusted shortlists with thresholds and role-fit notes; minimal false positives that waste practice reps.\n",
              "Scouting Dept: Augmentation (not replacement) of scouts; transparent feature importance and a feedback loop to correct misses.\n",
              "Analytics/ML: Reproducible, leakage-free pipeline with versioned data, drift/quality monitoring, and easy what-if analyses.\n",
              "Compliance/Legal: Fairness checks across demographics, privacy-safe data handling, and auditable decisions.\n",
              "IT/Ops: Secure access, low-latency scoring API, uptime during peak draft activity, and smooth integration with existing tools.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## C. Data Understanding"
      ],
      "metadata": {
        "id": "P0zsEPshwy1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.1   Load Datasets\n"
      ],
      "metadata": {
        "id": "sGMWhKSbUl63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from IPython.display import display\n",
        "\n",
        "# Search in root and sample_data (works in Colab)\n",
        "BASES = [Path(\".\"), Path(\"sample_data\"), Path(\"/content\"), Path(\"/content/sample_data\")]\n",
        "\n",
        "def find_file(name, required=False):\n",
        "    for b in BASES:\n",
        "        p = (b / name).resolve()\n",
        "        if p.exists(): return p\n",
        "    if required:\n",
        "        raise FileNotFoundError(f\"{name} not found in any of: \" + \", \".join(map(str, BASES)))\n",
        "    return None\n",
        "\n",
        "def read_csv_robust(path):\n",
        "    \"\"\"Try multiple encodings + safe options to avoid UnicodeDecodeError.\"\"\"\n",
        "    if path is None: return None\n",
        "    tried = []\n",
        "    for enc in [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin1\"]:\n",
        "        try:\n",
        "            return pd.read_csv(\n",
        "                path,\n",
        "                engine=\"python\",     # allows sep=None inference\n",
        "                sep=None,            # auto-detect delimiter\n",
        "                encoding=enc,\n",
        "                encoding_errors=\"replace\",  # keep going on bad bytes\n",
        "                on_bad_lines=\"skip\"  # skip broken rows if any\n",
        "            )\n",
        "        except Exception as e:\n",
        "            tried.append(f\"{enc}: {type(e).__name__}\")\n",
        "    print(f\"⚠️ Could not parse {path.name} with encodings -> {tried}. Skipping.\")\n",
        "    return None\n",
        "\n",
        "train_path  = find_file(\"train.csv\", required=True)\n",
        "test_path   = find_file(\"test.csv\",  required=True)\n",
        "sample_path = find_file(\"sample_submission.csv\", required=False)\n",
        "meta_path   = find_file(\"metadata.csv\", required=False)\n",
        "\n",
        "train = read_csv_robust(train_path)\n",
        "test  = read_csv_robust(test_path)\n",
        "sample_submission = read_csv_robust(sample_path)\n",
        "metadata = read_csv_robust(meta_path)\n",
        "\n",
        "print(\"Train:\", train_path, \"shape:\", train.shape)\n",
        "print(\"Test :\", test_path,  \"shape:\", test.shape)\n",
        "print(\"Sample submission:\", sample_path if sample_submission is not None else \"not found or unreadable\")\n",
        "print(\"Metadata:\", meta_path if metadata is not None else \"not found or unreadable\")\n",
        "\n",
        "display(train.head(3))\n",
        "display(test.head(3))"
      ],
      "metadata": {
        "id": "NKgOzSn-w0eq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "36a8ce31-fdc5-4014-db9a-39c3e4d9d72c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: /content/train.csv shape: (14774, 62)\n",
            "Test : /content/test.csv shape: (1297, 61)\n",
            "Sample submission: /content/sample_submission.csv\n",
            "Metadata: /content/metadata.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                team  conf  GP  Min_per   Ortg   usg   eFG  TS_per  ORB_per  \\\n",
              "0            Pacific    BW  26     52.6  111.8  19.3  61.8   64.93      1.1   \n",
              "1        Mississippi   SEC   2      0.8   63.6  29.6  33.3   33.33      0.0   \n",
              "2  Stephen F. Austin  Slnd   4      0.6   61.4  21.7  50.0   50.00      0.0   \n",
              "\n",
              "   DRB_per  ...    dgbpm    oreb    dreb    treb     ast     stl     blk  \\\n",
              "0      7.5  ... -1.34201  0.2308  1.5769  1.8077  2.2308  0.6538  0.0769   \n",
              "1     21.5  ... -5.42104  0.0000  1.0000  1.0000  0.0000  0.0000  0.0000   \n",
              "2      0.0  ...  6.46650  0.0000  0.0000  0.0000  0.0000  0.2500  0.0000   \n",
              "\n",
              "      pts                             player_id  drafted  \n",
              "0  9.6538  681edf6e-41cb-4fd1-ba91-da573e063fbc      0.0  \n",
              "1  2.0000  3542dcb7-19ad-47f2-8b3a-eb79eb3ec4c4      0.0  \n",
              "2  0.5000  ca0d8700-807d-4fce-a7a9-63922d1981e6      0.0  \n",
              "\n",
              "[3 rows x 62 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-175b9b4b-e518-4452-b362-33c52a4e17e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team</th>\n",
              "      <th>conf</th>\n",
              "      <th>GP</th>\n",
              "      <th>Min_per</th>\n",
              "      <th>Ortg</th>\n",
              "      <th>usg</th>\n",
              "      <th>eFG</th>\n",
              "      <th>TS_per</th>\n",
              "      <th>ORB_per</th>\n",
              "      <th>DRB_per</th>\n",
              "      <th>...</th>\n",
              "      <th>dgbpm</th>\n",
              "      <th>oreb</th>\n",
              "      <th>dreb</th>\n",
              "      <th>treb</th>\n",
              "      <th>ast</th>\n",
              "      <th>stl</th>\n",
              "      <th>blk</th>\n",
              "      <th>pts</th>\n",
              "      <th>player_id</th>\n",
              "      <th>drafted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pacific</td>\n",
              "      <td>BW</td>\n",
              "      <td>26</td>\n",
              "      <td>52.6</td>\n",
              "      <td>111.8</td>\n",
              "      <td>19.3</td>\n",
              "      <td>61.8</td>\n",
              "      <td>64.93</td>\n",
              "      <td>1.1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.34201</td>\n",
              "      <td>0.2308</td>\n",
              "      <td>1.5769</td>\n",
              "      <td>1.8077</td>\n",
              "      <td>2.2308</td>\n",
              "      <td>0.6538</td>\n",
              "      <td>0.0769</td>\n",
              "      <td>9.6538</td>\n",
              "      <td>681edf6e-41cb-4fd1-ba91-da573e063fbc</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mississippi</td>\n",
              "      <td>SEC</td>\n",
              "      <td>2</td>\n",
              "      <td>0.8</td>\n",
              "      <td>63.6</td>\n",
              "      <td>29.6</td>\n",
              "      <td>33.3</td>\n",
              "      <td>33.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.5</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.42104</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>3542dcb7-19ad-47f2-8b3a-eb79eb3ec4c4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Stephen F. Austin</td>\n",
              "      <td>Slnd</td>\n",
              "      <td>4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>61.4</td>\n",
              "      <td>21.7</td>\n",
              "      <td>50.0</td>\n",
              "      <td>50.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.46650</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>ca0d8700-807d-4fce-a7a9-63922d1981e6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 62 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-175b9b4b-e518-4452-b362-33c52a4e17e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-175b9b4b-e518-4452-b362-33c52a4e17e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-175b9b4b-e518-4452-b362-33c52a4e17e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-31195533-6973-4572-9ffb-49ce06eec3ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31195533-6973-4572-9ffb-49ce06eec3ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-31195533-6973-4572-9ffb-49ce06eec3ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        team  conf  GP  Min_per   Ortg   usg   eFG  TS_per  ORB_per  DRB_per  \\\n",
              "0   UC Davis    BW   8      2.2   51.7  13.4  30.0   30.00      0.0     14.3   \n",
              "1   Campbell  BSth  25     16.4   85.0  25.2  50.0   52.10      2.0     11.8   \n",
              "2  Weber St.  BSky  29     50.5  117.8  16.8  61.8   59.77     12.3     17.1   \n",
              "\n",
              "   ...      ogbpm     dgbpm    oreb    dreb    treb     ast     stl     blk  \\\n",
              "0  ... -11.240100 -4.721030  0.1000  0.6000  0.7000  0.2000  0.1000  0.0000   \n",
              "1  ...  -2.972020 -1.741870  0.1481  0.9259  1.0741  0.1481  0.4074  0.1111   \n",
              "2  ...   0.739055 -0.259202  2.1562  2.7500  4.9062  0.7188  0.4062  1.0625   \n",
              "\n",
              "      pts                             player_id  \n",
              "0  1.5000  c6d3ce49-28b6-4756-8061-b2bd68730c52  \n",
              "1  4.0741  24dd0ae2-9d22-4d31-9cb6-c31f58f903b5  \n",
              "2  6.7500  0cf3e822-9446-4285-b7ed-7c19d8e976fe  \n",
              "\n",
              "[3 rows x 61 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c1894aa-359a-4bc4-91f0-293b7123a1bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team</th>\n",
              "      <th>conf</th>\n",
              "      <th>GP</th>\n",
              "      <th>Min_per</th>\n",
              "      <th>Ortg</th>\n",
              "      <th>usg</th>\n",
              "      <th>eFG</th>\n",
              "      <th>TS_per</th>\n",
              "      <th>ORB_per</th>\n",
              "      <th>DRB_per</th>\n",
              "      <th>...</th>\n",
              "      <th>ogbpm</th>\n",
              "      <th>dgbpm</th>\n",
              "      <th>oreb</th>\n",
              "      <th>dreb</th>\n",
              "      <th>treb</th>\n",
              "      <th>ast</th>\n",
              "      <th>stl</th>\n",
              "      <th>blk</th>\n",
              "      <th>pts</th>\n",
              "      <th>player_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UC Davis</td>\n",
              "      <td>BW</td>\n",
              "      <td>8</td>\n",
              "      <td>2.2</td>\n",
              "      <td>51.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>30.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.3</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.240100</td>\n",
              "      <td>-4.721030</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.2000</td>\n",
              "      <td>0.1000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>c6d3ce49-28b6-4756-8061-b2bd68730c52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Campbell</td>\n",
              "      <td>BSth</td>\n",
              "      <td>25</td>\n",
              "      <td>16.4</td>\n",
              "      <td>85.0</td>\n",
              "      <td>25.2</td>\n",
              "      <td>50.0</td>\n",
              "      <td>52.10</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.8</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.972020</td>\n",
              "      <td>-1.741870</td>\n",
              "      <td>0.1481</td>\n",
              "      <td>0.9259</td>\n",
              "      <td>1.0741</td>\n",
              "      <td>0.1481</td>\n",
              "      <td>0.4074</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>4.0741</td>\n",
              "      <td>24dd0ae2-9d22-4d31-9cb6-c31f58f903b5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Weber St.</td>\n",
              "      <td>BSky</td>\n",
              "      <td>29</td>\n",
              "      <td>50.5</td>\n",
              "      <td>117.8</td>\n",
              "      <td>16.8</td>\n",
              "      <td>61.8</td>\n",
              "      <td>59.77</td>\n",
              "      <td>12.3</td>\n",
              "      <td>17.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.739055</td>\n",
              "      <td>-0.259202</td>\n",
              "      <td>2.1562</td>\n",
              "      <td>2.7500</td>\n",
              "      <td>4.9062</td>\n",
              "      <td>0.7188</td>\n",
              "      <td>0.4062</td>\n",
              "      <td>1.0625</td>\n",
              "      <td>6.7500</td>\n",
              "      <td>0cf3e822-9446-4285-b7ed-7c19d8e976fe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 61 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c1894aa-359a-4bc4-91f0-293b7123a1bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c1894aa-359a-4bc4-91f0-293b7123a1bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c1894aa-359a-4bc4-91f0-293b7123a1bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-233acf7a-277d-4173-80de-a3ea56849da6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-233acf7a-277d-4173-80de-a3ea56849da6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-233acf7a-277d-4173-80de-a3ea56849da6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.2 Define Target variable"
      ],
      "metadata": {
        "id": "tpG_mos_EXrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ID_COL = \"player_id\"\n",
        "TARGET_COL = \"drafted\"\n",
        "\n",
        "assert ID_COL in train.columns, f\"Missing {ID_COL} in train\"\n",
        "assert ID_COL in test.columns,  f\"Missing {ID_COL} in test\"\n",
        "assert TARGET_COL in train.columns, f\"Missing {TARGET_COL} in train\"\n",
        "\n",
        "print(\"Target dtype:\", train[TARGET_COL].dtype)\n",
        "print(\"Unique target values:\", sorted(train[TARGET_COL].dropna().unique().tolist()))\n",
        "print(\"Prevalence drafted=1:\", float(train[TARGET_COL].mean()))\n"
      ],
      "metadata": {
        "id": "gsQkuxYLVHb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e3f99dae-b67b-4329-84c9-2d9a2c52b32f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target dtype: float64\n",
            "Unique target values: [0.0, 1.0]\n",
            "Prevalence drafted=1: 0.007987004196561526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_definition_explanations = (\n",
        "    \"`drafted` is the target: 1 = drafted this season, 0 = not drafted.\\n\"\n",
        "    \"We predict a probability (0–1) for each player_id and submit two columns: player_id, drafted (probability).\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "RiqBkEQ-EjIZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='target_definition_explanations', value=target_definition_explanations)"
      ],
      "metadata": {
        "id": "qdeiAKiIElvG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "0dd6f7ac-b7e1-4b10-b327-8f64c8013085"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">target_definition_explanations</p><h3 font-size: 3em>`drafted` is the target: 1 = drafted this season, 0 = not drafted.\n",
              "We predict a probability (0–1) for each player_id and submit two columns: player_id, drafted (probability).</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.3 Create Target variable"
      ],
      "metadata": {
        "id": "CtIfwnLmEn51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ID_COL, TARGET_COL = \"player_id\", \"drafted\"\n",
        "\n",
        "# checks\n",
        "assert ID_COL in train.columns,  f\"Missing {ID_COL} in train\"\n",
        "assert TARGET_COL in train.columns, f\"Missing {TARGET_COL} in train\"\n",
        "\n",
        "# clean target to 0/1 ints (handles strings/NaNs safely)\n",
        "train[TARGET_COL] = (\n",
        "    pd.to_numeric(train[TARGET_COL], errors=\"coerce\")\n",
        "      .fillna(0).clip(0, 1).astype(int)\n",
        ")\n",
        "\n",
        "# quick stats\n",
        "pos = int(train[TARGET_COL].sum()); neg = len(train) - pos\n",
        "rate = pos / len(train)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANSWER — Create Target (NB2)\")\n",
        "print(f\"positives={pos} | negatives={neg} | drafted_rate={rate:.3f}\")\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "XV8dRa59EpLG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4e81db0a-fe4d-431c-f2cd-c119e3e6a759"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — Create Target (NB2)\n",
            "positives=118 | negatives=14656 | drafted_rate=0.008\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.4 Explore Target variable"
      ],
      "metadata": {
        "id": "dmSKLrSBFAN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TARGET_COL = \"drafted\"\n",
        "vc = train[TARGET_COL].value_counts().sort_index()\n",
        "rate = float(train[TARGET_COL].mean())\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANSWER — C.4 Target distribution\")\n",
        "print(vc.to_string())\n",
        "print(f\"drafted_rate: {rate:.3f}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# (optional) quick bar plot\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    vc.plot(kind=\"bar\"); plt.title(\"Target distribution\"); plt.xlabel(TARGET_COL); plt.ylabel(\"count\"); plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Plot skipped:\", e)\n",
        "\n",
        "# 2-line explanation\n",
        "target_distribution_explanations = (\n",
        "    \"The target is imbalanced; we’ll use stratified splits and AUROC to judge ranking quality.\\n\"\n",
        "    \"RF handles skew via class_weight='balanced_subsample' to reduce bias toward the majority class.\"\n",
        ")\n",
        "try:\n",
        "    print_title(size=\"h3\", key=\"target_distribution_explanations\", value=target_distribution_explanations)\n",
        "except NameError:\n",
        "    from IPython.display import Markdown, display\n",
        "    display(Markdown(\"### target_distribution_explanations\\n\" + target_distribution_explanations))\n"
      ],
      "metadata": {
        "id": "zeldOL0KFC4E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "34267add-9f0a-451e-942b-1ac013c56784"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — C.4 Target distribution\n",
            "drafted\n",
            "0    14656\n",
            "1      118\n",
            "drafted_rate: 0.008\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### target_distribution_explanations\nThe target is imbalanced; we’ll use stratified splits and AUROC to judge ranking quality.\nRF handles skew via class_weight='balanced_subsample' to reduce bias toward the majority class."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "target_distribution_explanations = \"\"\"\n",
        " The target is imbalanced; we’ll use stratified splits and AUROC to judge ranking quality.\\n\n",
        "    RF handles skew via class_weight='balanced_subsample' to reduce bias toward the majority class.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5I9ccv-UEr5o"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='target_distribution_explanations', value=target_distribution_explanations)"
      ],
      "metadata": {
        "id": "i45S7xA9EtEV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "468981a6-2153-481c-fefe-de4f6fb3a515"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">target_distribution_explanations</p><h3 font-size: 3em>\n",
              " The target is imbalanced; we’ll use stratified splits and AUROC to judge ranking quality.\n",
              "\n",
              "    RF handles skew via class_weight='balanced_subsample' to reduce bias toward the majority class.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.5 Explore Feature of Interest `\\<put feature name here\\>`"
      ],
      "metadata": {
        "id": "37ubEa7SFWXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ID_COL, TARGET_COL = \"player_id\", \"drafted\"\n",
        "feature_name = None   # <-- e.g. \"PTS\" or \"position\"; leave None to auto-pick\n",
        "\n",
        "# pick a feature if not provided\n",
        "candidates = [c for c in train.columns if c not in [ID_COL, TARGET_COL]]\n",
        "if feature_name is None or feature_name not in train.columns:\n",
        "    # prefer a numeric; otherwise first categorical\n",
        "    nums = [c for c in candidates if pd.api.types.is_numeric_dtype(train[c])]\n",
        "    feature_name = (nums[0] if nums else candidates[0])\n",
        "\n",
        "s = train[feature_name]\n",
        "missing = s.isna().mean()\n",
        "nuniq = s.nunique(dropna=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"ANSWER — C.5 Feature: {feature_name}\")\n",
        "print(f\"dtype={s.dtype} | unique={nuniq} | missing={missing:.2%}\")\n",
        "\n",
        "if pd.api.types.is_numeric_dtype(s):\n",
        "    desc = s.describe(percentiles=[.05,.50,.95]).to_string()\n",
        "    # correlation with target (drop NaNs)\n",
        "    corr = train[[feature_name, TARGET_COL]].dropna().corr().iloc[0,1]\n",
        "    print(\"--- summary ---\")\n",
        "    print(desc)\n",
        "    print(f\"corr({feature_name}, {TARGET_COL}) = {corr:.3f}\")\n",
        "else:\n",
        "    print(\"--- top categories ---\")\n",
        "    print(s.value_counts(dropna=False).head(10).to_string())\n",
        "    if TARGET_COL in train.columns:\n",
        "        rate = train.groupby(feature_name, dropna=False)[TARGET_COL].mean().sort_values(ascending=False).head(10)\n",
        "        print(\"--- drafted rate by category (top 10) ---\")\n",
        "        print(rate.to_string())\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "wV9Ldx0gFWks",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8ea1bf20-2dec-46c4-bc4e-b3845409ff08"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — C.5 Feature: GP\n",
            "dtype=int64 | unique=41 | missing=0.00%\n",
            "--- summary ---\n",
            "count    14774.000000\n",
            "mean        21.251726\n",
            "std         10.517642\n",
            "min          1.000000\n",
            "5%           3.000000\n",
            "50%         25.000000\n",
            "95%         34.000000\n",
            "max         41.000000\n",
            "corr(GP, drafted) = 0.109\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_1_insights = \"\"\"\n",
        "We inspect distribution, missingness, and relationship with `drafted` to judge signal and leakage risk.\\n\n",
        "    Findings guide encoding (scale/one-hot), imputation, and whether to keep or drop the feature.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "y4YLcn_eEyAe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_1_insights', value=feature_1_insights)"
      ],
      "metadata": {
        "id": "2r1knRxDEyC0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "a8ecd3b7-c6ff-4acc-f498-9b5b566a7865"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_1_insights</p><h3 font-size: 3em>\n",
              "We inspect distribution, missingness, and relationship with `drafted` to judge signal and leakage risk.\n",
              "\n",
              "    Findings guide encoding (scale/one-hot), imputation, and whether to keep or drop the feature.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.6 Explore Feature of Interest `\\<put feature name here\\>`"
      ],
      "metadata": {
        "id": "WOqd56IjE0LB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ID_COL, TARGET_COL = globals().get(\"ID_COL\", \"player_id\"), globals().get(\"TARGET_COL\", \"drafted\")\n",
        "\n",
        "# 👉 Set a specific column name here (or leave None to auto-pick a different one from C.5)\n",
        "feature_name2 = None\n",
        "\n",
        "# Build candidate list (avoid ID/target and avoid the feature used in C.5 if present)\n",
        "candidates = [c for c in train.columns if c not in [ID_COL, TARGET_COL]]\n",
        "if \"feature_name\" in globals() and isinstance(feature_name, str) and feature_name in candidates:\n",
        "    candidates = [c for c in candidates if c != feature_name]\n",
        "\n",
        "# Auto-pick: prefer numeric, else first available\n",
        "if not candidates:\n",
        "    raise ValueError(\"No candidate features found to explore.\")\n",
        "nums = [c for c in candidates if pd.api.types.is_numeric_dtype(train[c])]\n",
        "feature_name2 = feature_name2 if (feature_name2 in train.columns) else (nums[0] if nums else candidates[0])\n",
        "\n",
        "s = train[feature_name2]\n",
        "missing = s.isna().mean()\n",
        "nuniq = s.nunique(dropna=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"ANSWER — C.6 Feature: {feature_name2}\")\n",
        "print(f\"dtype={s.dtype} | unique={nuniq} | missing={missing:.2%}\")\n",
        "\n",
        "if pd.api.types.is_numeric_dtype(s):\n",
        "    desc = s.describe(percentiles=[.05, .50, .95]).to_string()\n",
        "    corr = train[[feature_name2, TARGET_COL]].dropna().corr().iloc[0, 1]\n",
        "    print(\"--- summary ---\")\n",
        "    print(desc)\n",
        "    print(f\"corr({feature_name2}, {TARGET_COL}) = {corr:.3f}\")\n",
        "else:\n",
        "    print(\"--- top categories ---\")\n",
        "    print(s.value_counts(dropna=False).head(10).to_string())\n",
        "    if TARGET_COL in train.columns:\n",
        "        rate = train.groupby(feature_name2, dropna=False)[TARGET_COL].mean().sort_values(ascending=False).head(10)\n",
        "        print(\"--- drafted rate by category (top 10) ---\")\n",
        "        print(rate.to_string())\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "akQFJsI3E2eM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d26e266d-fd58-46cf-8af9-7ccfc10e7fbe"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — C.6 Feature: Min_per\n",
            "dtype=float64 | unique=887 | missing=0.00%\n",
            "--- summary ---\n",
            "count    14774.000000\n",
            "mean        25.870123\n",
            "std         23.639878\n",
            "min          0.000000\n",
            "5%           0.300000\n",
            "50%         19.600000\n",
            "95%         72.000000\n",
            "max         94.300000\n",
            "corr(Min_per, drafted) = 0.153\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_2_insights =  \"\"\"\n",
        "We repeat the check on another feature: distribution, missingness, and link to `drafted` to judge signal.\n",
        "This helps decide encoding (one-hot/scale), imputation, and whether to keep or drop the feature.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "u-CfAsO1E2hB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_2_insights', value=feature_2_insights)"
      ],
      "metadata": {
        "id": "bB87lgCAE2jf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "30599f75-a6e4-444b-c65a-4b052d47dd2e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_2_insights</p><h3 font-size: 3em>\n",
              "We repeat the check on another feature: distribution, missingness, and link to `drafted` to judge signal.\n",
              "This helps decide encoding (one-hot/scale), imputation, and whether to keep or drop the feature.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### C.n Explore Feature of Interest `\\<put feature name here\\>`\n",
        "\n",
        "> You can add more cells related to other feeatures in this section"
      ],
      "metadata": {
        "id": "ZcjaUGQ_VbVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C.n — Explore Feature of Interest (NB2)\n",
        "import pandas as pd\n",
        "\n",
        "ID_COL, TARGET_COL = globals().get(\"ID_COL\",\"player_id\"), globals().get(\"TARGET_COL\",\"drafted\")\n",
        "\n",
        "# 👉 Set a specific column name here (or leave None to auto-pick a new one)\n",
        "feature_name_n = None\n",
        "\n",
        "# Avoid ID/target and any features explored earlier (feature_name, feature_name2)\n",
        "used = {ID_COL, TARGET_COL}\n",
        "for n in [\"feature_name\", \"feature_name2\", \"feature_1\", \"feature_2\", \"feature_n\"]:\n",
        "    if n in globals() and isinstance(globals()[n], str):\n",
        "        used.add(globals()[n])\n",
        "\n",
        "candidates = [c for c in train.columns if c not in used]\n",
        "if not candidates:\n",
        "    raise ValueError(\"No new candidate features left to explore.\")\n",
        "\n",
        "# Prefer numeric, else first available\n",
        "nums = [c for c in candidates if pd.api.types.is_numeric_dtype(train[c])]\n",
        "feature_name_n = feature_name_n if (feature_name_n in train.columns) else (nums[0] if nums else candidates[0])\n",
        "\n",
        "s = train[feature_name_n]\n",
        "missing = s.isna().mean()\n",
        "nuniq = s.nunique(dropna=True)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(f\"ANSWER — C.n Feature: {feature_name_n}\")\n",
        "print(f\"dtype={s.dtype} | unique={nuniq} | missing={missing:.2%}\")\n",
        "\n",
        "if pd.api.types.is_numeric_dtype(s):\n",
        "    desc = s.describe(percentiles=[.05,.50,.95]).to_string()\n",
        "    corr = train[[feature_name_n, TARGET_COL]].dropna().corr().iloc[0,1]\n",
        "    print(\"--- summary ---\")\n",
        "    print(desc)\n",
        "    print(f\"corr({feature_name_n}, {TARGET_COL}) = {corr:.3f}\")\n",
        "else:\n",
        "    print(\"--- top categories ---\")\n",
        "    print(s.value_counts(dropna=False).head(10).to_string())\n",
        "    if TARGET_COL in train.columns:\n",
        "        rate = train.groupby(feature_name_n, dropna=False)[TARGET_COL].mean().sort_values(ascending=False).head(10)\n",
        "        print(\"--- drafted rate by category (top 10) ---\")\n",
        "        print(rate.to_string())\n",
        "print(\"=\"*60)\n"
      ],
      "metadata": {
        "id": "Z_DwQMvDVbfA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "adf7e8c0-6673-4b31-e6d7-e00587132a96"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — C.n Feature: Ortg\n",
            "dtype=float64 | unique=1332 | missing=0.00%\n",
            "--- summary ---\n",
            "count    14774.000000\n",
            "mean        85.771707\n",
            "std         34.164203\n",
            "min          0.000000\n",
            "5%           0.000000\n",
            "50%         91.300000\n",
            "95%        120.800000\n",
            "max        407.300000\n",
            "corr(Ortg, drafted) = 0.065\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_n_insight_explanations = \"\"\"\n",
        "We inspect another (new) feature’s distribution, missingness, and its link to `drafted` to gauge signal.\n",
        "This helps decide encoding/imputation and whether to keep, bucket, or drop the feature.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Cg6t9Tqg3mZ-"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_2_insights', value=feature_n_insight_explanations )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "bvQOwrbu3rRb",
        "outputId": "b8327c99-2412-4cb7-cfba-a18749867e2f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_2_insights</p><h3 font-size: 3em>\n",
              "We inspect another (new) feature’s distribution, missingness, and its link to `drafted` to gauge signal.\n",
              "This helps decide encoding/imputation and whether to keep, bucket, or drop the feature.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NCwQQFkU3v5"
      },
      "source": [
        "---\n",
        "## D. Feature Selection\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.1 Approach \"\\<describe_approach_here\\>\"\n"
      ],
      "metadata": {
        "id": "0b8C9WON3Toe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "print(\"scikit-learn version:\", sklearn.__version__)"
      ],
      "metadata": {
        "id": "J2_6it8iViBX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d0580695-f292-4b9b-acbe-139566b97a2c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scikit-learn version: 1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"len(train) =\", len(train))\n",
        "for n in [\"y\",\"y_train\",\"y_valid\",\"y_tr\",\"y_va\"]:\n",
        "    if n in globals():\n",
        "        try: print(n, len(globals()[n]))\n",
        "        except: pass\n",
        "for n in [\"X_tr\",\"X_train\",\"X_full\",\"X_train_d1\"]:\n",
        "    if n in globals():\n",
        "        try: print(n, globals()[n].shape)\n",
        "        except: pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WLBLdbKo5UYQ",
        "outputId": "9484d07e-f9ab-4175-ad0a-78222b3e3079"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train) = 14774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "ID_COL     = globals().get(\"ID_COL\",\"player_id\")\n",
        "TARGET_COL = globals().get(\"TARGET_COL\",\"drafted\")\n",
        "\n",
        "# Base frames (drop train-only cols like cv_fold)\n",
        "TRAIN_ONLY = [\"cv_fold\",\"fold\",\"kfold\"]\n",
        "Xb_tr_raw = train.drop(columns=[c for c in [TARGET_COL, ID_COL] + TRAIN_ONLY if c in train.columns], errors=\"ignore\")\n",
        "Xb_te_raw = test.drop(columns=[ID_COL], errors=\"ignore\")\n",
        "\n",
        "# keep only columns present in BOTH\n",
        "common_cols = sorted(set(Xb_tr_raw.columns) & set(Xb_te_raw.columns))\n",
        "Xb_tr = Xb_tr_raw[common_cols].copy()\n",
        "Xb_te = Xb_te_raw[common_cols].copy()\n",
        "\n",
        "# one-hot together → split back\n",
        "X_all = pd.get_dummies(pd.concat([Xb_tr, Xb_te], axis=0, ignore_index=True), dummy_na=True)\n",
        "X_tr  = X_all.iloc[:len(train)].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
        "X_te  = X_all.iloc[len(train):].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
        "\n",
        "# FULL y aligned to X_tr\n",
        "y_all = train[TARGET_COL].astype(int).reset_index(drop=True)\n",
        "\n",
        "assert len(X_tr) == len(y_all), f\"Mismatch after reset: X_tr={len(X_tr)} vs y_all={len(y_all)}\"\n",
        "\n",
        "# Example: RF importances on FULL data\n",
        "rf = RandomForestClassifier(n_estimators=400, min_samples_leaf=2,\n",
        "                            class_weight=\"balanced_subsample\", n_jobs=-1, random_state=42)\n",
        "rf.fit(X_tr, y_all)\n",
        "\n",
        "imp = pd.Series(rf.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
        "TOP_K = min(40, X_tr.shape[1])\n",
        "selected_features_d1 = imp.head(TOP_K).index.tolist()\n",
        "\n",
        "X_train_d1 = X_tr[selected_features_d1]\n",
        "X_test_d1  = X_te[selected_features_d1]\n",
        "\n",
        "print(\"OK → D.1 ready. Shapes:\", X_train_d1.shape, X_test_d1.shape)"
      ],
      "metadata": {
        "id": "zfC-DLKv4AuM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bfd3e64d-9c22-4ec0-ae60-7e6f2ef04008"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK → D.1 ready. Shapes: (14774, 40) (1297, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "ID_COL     = globals().get(\"ID_COL\", \"player_id\")\n",
        "TARGET_COL = globals().get(\"TARGET_COL\", \"drafted\")\n",
        "\n",
        "# Build aligned numeric matrix (drop target/ID and train-only cols like cv_fold)\n",
        "TRAIN_ONLY = [\"cv_fold\", \"fold\", \"kfold\"]\n",
        "Xb_tr_raw = train.drop(columns=[c for c in [TARGET_COL, ID_COL] + TRAIN_ONLY if c in train.columns], errors=\"ignore\")\n",
        "Xb_te_raw = test.drop(columns=[ID_COL], errors=\"ignore\")\n",
        "common_cols = sorted(set(Xb_tr_raw.columns) & set(Xb_te_raw.columns))\n",
        "X_all = pd.get_dummies(pd.concat([Xb_tr_raw[common_cols], Xb_te_raw[common_cols]], axis=0, ignore_index=True), dummy_na=True)\n",
        "\n",
        "X_tr = X_all.iloc[:len(train)].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "X_te = X_all.iloc[len(train):].replace([np.inf, -np.inf], np.nan).fillna(0)\n",
        "y_all = train[TARGET_COL].astype(int).reset_index(drop=True)\n",
        "\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=400, min_samples_leaf=2, max_features=\"sqrt\",\n",
        "    class_weight=\"balanced_subsample\", n_jobs=-1, random_state=42\n",
        ").fit(X_tr, y_all)\n",
        "\n",
        "imp = pd.Series(rf.feature_importances_, index=X_tr.columns).sort_values(ascending=False)\n",
        "TOP_K = min(60, X_tr.shape[1])\n",
        "selected_features_d1 = imp.head(TOP_K).index.tolist()\n",
        "\n",
        "X_train_d1 = X_tr[selected_features_d1].copy()\n",
        "X_test_d1  = X_te[selected_features_d1].copy()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANSWER — D.1 RF top features:\", selected_features_d1[:10], \"...\" if len(selected_features_d1)>10 else \"\")\n",
        "print(\"Shapes → X_train_d1:\", X_train_d1.shape, \"| X_test_d1:\", X_test_d1.shape)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hbzH6j2a6FwX",
        "outputId": "58e86d3f-0cd5-4447-c48b-a98a9a3b378d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — D.1 RF top features: ['Rec_Rank', 'dporpag', 'bpm', 'gbpm', 'porpag', 'dreb', 'twoPA', 'adjoe', 'pts', 'rimmade'] ...\n",
            "Shapes → X_train_d1: (14774, 60) | X_test_d1: (1297, 60)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_selection_1_insights = \"\"\"\n",
        "Use RandomForest importances to keep the strongest K features.\n",
        "This captures non-linear signal and removes noise for faster training.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z9myLlFZFQXj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_selection_1_insights', value=feature_selection_1_insights)"
      ],
      "metadata": {
        "id": "937YFeqDFQgB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b85f4ebb-d1eb-440a-81db-d541c7c075e5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_selection_1_insights</p><h3 font-size: 3em>\n",
              "Use RandomForest importances to keep the strongest K features.\n",
              "This captures non-linear signal and removes noise for faster training.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### D.2 Approach \"\\<describe_approach_here\\>\"\n"
      ],
      "metadata": {
        "id": "jqRcgUqu3ZuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Reuse matrices from D.1 if present; otherwise build them\n",
        "if \"X_tr\" not in globals() or \"X_te\" not in globals():\n",
        "    ID_COL     = globals().get(\"ID_COL\", \"player_id\")\n",
        "    TARGET_COL = globals().get(\"TARGET_COL\", \"drafted\")\n",
        "    TRAIN_ONLY = [\"cv_fold\", \"fold\", \"kfold\"]\n",
        "    Xb_tr_raw = train.drop(columns=[c for c in [TARGET_COL, ID_COL] + TRAIN_ONLY if c in train.columns], errors=\"ignore\")\n",
        "    Xb_te_raw = test.drop(columns=[ID_COL], errors=\"ignore\")\n",
        "    common_cols = sorted(set(Xb_tr_raw.columns) & set(Xb_te_raw.columns))\n",
        "    X_all = pd.get_dummies(pd.concat([Xb_tr_raw[common_cols], Xb_te_raw[common_cols]], axis=0, ignore_index=True), dummy_na=True)\n",
        "    X_tr = X_all.iloc[:len(train)].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
        "    X_te = X_all.iloc[len(train):].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
        "\n",
        "y_all = train[TARGET_COL].astype(int).reset_index(drop=True)\n",
        "\n",
        "# Low-cardinality columns treated as discrete for MI\n",
        "disc = [(X_tr[c].nunique() < 20) for c in X_tr.columns]\n",
        "mi = mutual_info_classif(X_tr, y_all, discrete_features=disc, random_state=42)\n",
        "mi_s = pd.Series(mi, index=X_tr.columns).sort_values(ascending=False)\n",
        "\n",
        "TOP_K = min(60, X_tr.shape[1])\n",
        "selected_features_d2 = mi_s.head(TOP_K).index.tolist()\n",
        "\n",
        "X_train_d2 = X_tr[selected_features_d2].copy()\n",
        "X_test_d2  = X_te[selected_features_d2].copy()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANSWER — D.2 MI top features:\", selected_features_d2[:10], \"...\" if len(selected_features_d2)>10 else \"\")\n",
        "print(\"Shapes → X_train_d2:\", X_train_d2.shape, \"| X_test_d2:\", X_test_d2.shape)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "dAPSiwcg3aJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4ff1687e-4ea0-4a74-b100-54e7475ab52a"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — D.2 MI top features: ['Rec_Rank', 'dporpag', 'stops', 'porpag', 'twoPM', 'bpm', 'FTA', 'twoPA', 'gbpm', 'dreb'] ...\n",
            "Shapes → X_train_d2: (14774, 60) | X_test_d2: (1297, 60)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_selection_2_insights = \"\"\"\n",
        "Mutual Information ranks dependency with `drafted` without assuming linearity.\n",
        "We keep the top-K to compare against model-based selection.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CpQQodTW3a9v"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_selection_2_insights', value=feature_selection_2_insights)"
      ],
      "metadata": {
        "id": "HjN2qhDb3a0G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "06dd03b2-49e2-471f-c000-33a83c261698"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_selection_2_insights</p><h3 font-size: 3em>\n",
              "Mutual Information ranks dependency with `drafted` without assuming linearity.\n",
              "We keep the top-K to compare against model-based selection.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D.z Final Selection of Features"
      ],
      "metadata": {
        "id": "gS5-tS8_3ryn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# D.n — FAST: prefilter with ANOVA F, then L1-Logistic (liblinear)\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "ID_COL     = globals().get(\"ID_COL\", \"player_id\")\n",
        "TARGET_COL = globals().get(\"TARGET_COL\", \"drafted\")\n",
        "\n",
        "# Reuse aligned matrices if available; else build quickly (train-only cols removed)\n",
        "if \"X_tr\" not in globals() or \"X_te\" not in globals():\n",
        "    TRAIN_ONLY = [\"cv_fold\",\"fold\",\"kfold\"]\n",
        "    Xb_tr_raw = train.drop(columns=[c for c in [TARGET_COL, ID_COL] + TRAIN_ONLY if c in train.columns], errors=\"ignore\")\n",
        "    Xb_te_raw = test.drop(columns=[ID_COL], errors=\"ignore\")\n",
        "    common = sorted(set(Xb_tr_raw.columns) & set(Xb_te_raw.columns))\n",
        "    X_all = pd.get_dummies(pd.concat([Xb_tr_raw[common], Xb_te_raw[common]], axis=0, ignore_index=True), dummy_na=True)\n",
        "    X_tr = X_all.iloc[:len(train)].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
        "    X_te = X_all.iloc[len(train):].replace([np.inf,-np.inf], np.nan).fillna(0)\n",
        "\n",
        "y_all = train[TARGET_COL].astype(int).reset_index(drop=True)\n",
        "\n",
        "# 1) FAST PREFILTER — keep top K0 by ANOVA F-score (very fast)\n",
        "K0 = min(300, X_tr.shape[1])           # reduce to ≤300 cols first\n",
        "F, _ = f_classif(X_tr, y_all)          # handles dense arrays quickly\n",
        "order0 = np.argsort(-np.nan_to_num(F, nan=0.0))\n",
        "cols_pref = X_tr.columns[order0[:K0]]\n",
        "X_pf_tr = X_tr[cols_pref]\n",
        "X_pf_te = X_te[cols_pref]\n",
        "\n",
        "# 2) L1-LOGISTIC (small, quick)\n",
        "lr_l1 = LogisticRegression(\n",
        "    penalty=\"l1\", solver=\"liblinear\", C=0.5,\n",
        "    class_weight=\"balanced\", max_iter=300, tol=1e-3, random_state=42\n",
        ")\n",
        "lr_l1.fit(X_pf_tr, y_all)\n",
        "\n",
        "coef = lr_l1.coef_.ravel()\n",
        "abs_coef = np.abs(coef)\n",
        "nonzero = np.where(abs_coef > 1e-8)[0]\n",
        "\n",
        "TOP_K = min(60, len(cols_pref))        # final compact set\n",
        "keep_idx = (nonzero if len(nonzero) else np.argsort(-abs_coef)[:TOP_K])\n",
        "order = keep_idx[np.argsort(-abs_coef[keep_idx])] [:TOP_K]\n",
        "\n",
        "selected_features_dn = cols_pref[order].tolist()\n",
        "X_train_dn = X_pf_tr[selected_features_dn].copy()\n",
        "X_test_dn  = X_pf_te[selected_features_dn].copy()\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANSWER — D.n FAST (L1-Logistic) selected:\", len(selected_features_dn))\n",
        "print(\"First 12:\", selected_features_dn[:12], \"...\" if len(selected_features_dn)>12 else \"\")\n",
        "print(\"Shapes →\", X_train_dn.shape, X_test_dn.shape)\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "zYY4u2063ioF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b1bf7b0c-6d08-4aa6-83c3-00e2d7ba8dcf"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ANSWER — D.n FAST (L1-Logistic) selected: 60\n",
            "First 12: ['team_Marshall', 'team_Dayton', 'dporpag', 'team_Kentucky', 'ht_10-Jun', 'ast', 'team_Louisville', 'dunks_ratio', 'ht_11-Jun', 'conf_B10', 'team_Oklahoma', 'team_UCLA'] ...\n",
            "Shapes → (14774, 60) (1297, 60)\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_selection_explanations =  \"\"\"\n",
        "prefilter to top-K0 by ANOVA F, then L1-Logistic (liblinear) to keep a compact non-zero set.\n",
        "This slashes runtime while still giving sparse, high-signal features for modeling.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-pxVH1r63vqu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_selection_explanations', value=feature_selection_explanations)"
      ],
      "metadata": {
        "id": "rHluIUmR3iO3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "235b6a63-78ee-4d8a-8c03-3dff2bde8e98"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_selection_explanations</p><h3 font-size: 3em>\n",
              "prefilter to top-K0 by ANOVA F, then L1-Logistic (liblinear) to keep a compact non-zero set.\n",
              "This slashes runtime while still giving sparse, high-signal features for modeling.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## E. Data Preparation"
      ],
      "metadata": {
        "id": "j-nNSpJK0Rgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E.1 Data Transformation <put_name_here>"
      ],
      "metadata": {
        "id": "EDtRq1990rcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# E.1 — Build aligned feature matrices (one-hot + median impute) — short & robust\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# Show the files we loaded (if your earlier vars exist)\n",
        "try:\n",
        "    print(\"Using:\", train_path.name, \"|\", test_path.name)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Detect columns (defaults for this assignment)\n",
        "ID_COL = \"player_id\" if \"player_id\" in train.columns else next((c for c in [\"id\",\"ID\"] if c in train.columns), None)\n",
        "TARGET_COL = \"drafted\"  if \"drafted\"  in train.columns else next((c for c in [\"target\",\"label\"] if c in train.columns), None)\n",
        "\n",
        "# Drop non-features and keep only columns present in BOTH train & test\n",
        "TRAIN_ONLY = [c for c in [\"cv_fold\",\"fold\",\"kfold\"] if c in train.columns]\n",
        "drop_cols = [c for c in [TARGET_COL, ID_COL] + TRAIN_ONLY if c is not None]\n",
        "Xb_tr_raw = train.drop(columns=drop_cols, errors=\"ignore\")\n",
        "Xb_te_raw = test.drop(columns=[c for c in [ID_COL] if c is not None], errors=\"ignore\")\n",
        "common_cols = sorted(set(Xb_tr_raw.columns) & set(Xb_te_raw.columns))\n",
        "\n",
        "# One-hot encode together → split back; fix inf/NaN with train medians\n",
        "X_all = pd.get_dummies(pd.concat([Xb_tr_raw[common_cols], Xb_te_raw[common_cols]], axis=0, ignore_index=True),\n",
        "                       dummy_na=True)\n",
        "X_e1_tr = X_all.iloc[:len(train)].replace([np.inf,-np.inf], np.nan)\n",
        "X_e1_te = X_all.iloc[len(train):].replace([np.inf,-np.inf], np.nan)\n",
        "med = X_e1_tr.median(numeric_only=True)\n",
        "X_e1_tr = X_e1_tr.fillna(med)\n",
        "X_e1_te = X_e1_te.fillna(med)\n",
        "\n",
        "# Optional: expose generic names so later cells “just work”\n",
        "X_tr, X_te = X_e1_tr, X_e1_te\n",
        "X_train_model, X_test_model = X_e1_tr.copy(), X_e1_te.copy()\n",
        "features_list = list(X_train_model.columns)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ANSWER — E.1 ready\")\n",
        "print(\"Train/Test shapes:\", X_train_model.shape, \"|\", X_test_model.shape)\n",
        "print(\"First 8 features:\", features_list[:8])\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 2-line explanation\n",
        "e1_explain = (\n",
        "    \"We aligned train/test columns, one-hot encoded together, and filled missing values with train medians.\\n\"\n",
        "    \"Trees don’t need scaling, so this clean matrix is ready for splitting and modeling.\"\n",
        ")\n",
        "print(e1_explain)\n"
      ],
      "metadata": {
        "id": "OO5ITMDZ035_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a959cc5a-82a2-49c3-8b26-093304b894c2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: train.csv | test.csv\n",
            "============================================================\n",
            "ANSWER — E.1 ready\n",
            "Train/Test shapes: (14774, 488) | (1297, 488)\n",
            "First 8 features: ['AST_per', 'DRB_per', 'FTA', 'FTM', 'FT_per', 'GP', 'Min_per', 'ORB_per']\n",
            "============================================================\n",
            "We aligned train/test columns, one-hot encoded together, and filled missing values with train medians.\n",
            "Trees don’t need scaling, so this clean matrix is ready for splitting and modeling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_cleaning_1_explanations = \"\"\"\n",
        "Use the selected D.* feature set and fill missing values with train medians.\\n\n",
        "    RF doesn’t need scaling; simple imputation is enough.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eQGXvLtkFU9L"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_cleaning_1_explanations', value=data_cleaning_1_explanations)"
      ],
      "metadata": {
        "id": "MPuYme1uFU_4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "2a2c2773-6b6f-4975-fd40-14d2ded84d03"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_1_explanations</p><h3 font-size: 3em>\n",
              "Use the selected D.* feature set and fill missing values with train medians.\n",
              "\n",
              "    RF doesn’t need scaling; simple imputation is enough.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E.2 Data Transformation <put_name_here>"
      ],
      "metadata": {
        "id": "SxhDoAkw08Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Columns to clip = numeric only (exclude booleans)\n",
        "num_cols  = X_e1_tr.select_dtypes(include=[np.number]).columns\n",
        "bool_cols = X_e1_tr.select_dtypes(include=[\"bool\"]).columns\n",
        "num_cols  = num_cols.difference(bool_cols)\n",
        "\n",
        "# Train-only percentiles\n",
        "q_low  = X_e1_tr[num_cols].quantile(0.01)   # p1 on TRAIN\n",
        "q_high = X_e1_tr[num_cols].quantile(0.99)   # p99 on TRAIN\n",
        "\n",
        "# Copy, then clip only numeric columns; apply TRAIN bounds to TEST (no leakage)\n",
        "X_e2_tr = X_e1_tr.copy()\n",
        "X_e2_te = X_e1_te.copy()\n",
        "X_e2_tr[num_cols] = X_e1_tr[num_cols].clip(lower=q_low,  upper=q_high, axis=1)\n",
        "X_e2_te[num_cols] = X_e1_te[num_cols].clip(lower=q_low,  upper=q_high, axis=1)\n",
        "\n",
        "print(f\"ANSWER – E.2: clipped 1–99% on {len(num_cols)} numeric column(s); \"\n",
        "      f\"left {len(bool_cols)} boolean column(s) unchanged.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k9Ms7HklkUJY",
        "outputId": "77c80b4b-a0b4-4dcf-a327-2540790fe7ff"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER – E.2: clipped 1–99% on 55 numeric column(s); left 433 boolean column(s) unchanged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_cleaning_2_explanations = \"\"\"\n",
        "Why (Random Forest): Extreme numeric outliers can drive unstable / overly deep splits and add variance.\n",
        "What we did: Computed per-feature p1 and p99 on the TRAIN set (numeric, non-bool columns only),\n",
        "then clipped both TRAIN and TEST to those TRAIN-derived bounds.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NoQ6IWoFFb1y"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_cleaning_2_explanations', value=data_cleaning_2_explanations)"
      ],
      "metadata": {
        "id": "n1NG6O-jFdOE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "09efaabb-f45f-4e70-c9b9-03fe0fdaf24d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_2_explanations</p><h3 font-size: 3em>\n",
              "Why (Random Forest): Extreme numeric outliers can drive unstable / overly deep splits and add variance.\n",
              "What we did: Computed per-feature p1 and p99 on the TRAIN set (numeric, non-bool columns only),\n",
              "then clipped both TRAIN and TEST to those TRAIN-derived bounds.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E.3 Data Transformation <put_name_here>"
      ],
      "metadata": {
        "id": "ylQxO-4g03qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "# Transform only numeric (non-bool) columns\n",
        "num_cols  = X_e2_tr.select_dtypes(include=[np.number]).columns\n",
        "bool_cols = X_e2_tr.select_dtypes(include=[\"bool\"]).columns\n",
        "num_cols  = num_cols.difference(bool_cols)\n",
        "\n",
        "pt_e3 = PowerTransformer(method=\"yeo-johnson\", standardize=False)\n",
        "\n",
        "X_e3_tr = X_e2_tr.copy()\n",
        "X_e3_te = X_e2_te.copy()\n",
        "X_e3_tr[num_cols] = pt_e3.fit_transform(X_e2_tr[num_cols])   # fit on TRAIN\n",
        "X_e3_te[num_cols] = pt_e3.transform(X_e2_te[num_cols])       # transform TEST\n",
        "\n",
        "print(f\"ANSWER – E.3: Yeo-Johnson applied on {len(num_cols)} numeric column(s); \"\n",
        "      f\"left {len(bool_cols)} boolean column(s) unchanged.\")\n"
      ],
      "metadata": {
        "id": "5VymIZpS1Ch7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "39cca6d9-8f60-47ab-e53f-297eb55ab480"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER – E.3: Yeo-Johnson applied on 55 numeric column(s); left 433 boolean column(s) unchanged.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_cleaning_3_explanations = \"\"\" A power transform (Yeo–Johnson) reduces skew and stabilises variance, which can make tree splits less\n",
        "sensitive to extreme ranges while preserving monotonicity of features.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BHo46tqSFibl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_cleaning_3_explanations', value=data_cleaning_3_explanations)"
      ],
      "metadata": {
        "id": "D1BIohZLFiiM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "c2b62984-ac44-48c8-c7b5-cc3c3bdc1e2a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_cleaning_3_explanations</p><h3 font-size: 3em> A power transform (Yeo–Johnson) reduces skew and stabilises variance, which can make tree splits less\n",
              "sensitive to extreme ranges while preserving monotonicity of features.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### E.n Fixing \"\\<describe_issue_here\\>\"\n",
        "\n",
        "> You can add more cells related to other issues in this section"
      ],
      "metadata": {
        "id": "w8pDuIcQVxgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr = X_e3_tr   # final training features\n",
        "X_te = X_e3_te   # final test features\n",
        "\n",
        "print(\"ANSWER – E.n: X_tr/X_te set to E.3 outputs (clipping + Yeo–Johnson). Ready for RandomForest.\")"
      ],
      "metadata": {
        "id": "L7MGT74hVxm2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "883d4bbf-942d-45b9-c1ba-8494e3a8b37a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER – E.n: X_tr/X_te set to E.3 outputs (clipping + Yeo–Johnson). Ready for RandomForest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- J.alt2: Logistic Regression on top of E.3 (compact) ---\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# 0) labels + IDs\n",
        "ID_COL = \"player_id\" if \"player_id\" in train.columns else None\n",
        "TARGET_COL = \"drafted\" if \"drafted\" in train.columns else None\n",
        "assert TARGET_COL is not None, \"Need labels in train (column 'drafted').\"\n",
        "y_all = pd.to_numeric(train[TARGET_COL], errors=\"coerce\").fillna(0).astype(int).to_numpy()\n",
        "\n",
        "# 1) pick continuous cols (don’t scale one-hot 0/1s)\n",
        "cont_cols = [c for c in X_e3_tr.columns if X_e3_tr[c].nunique(dropna=True) > 2]\n",
        "\n",
        "X_tr_df = X_e3_tr.copy()\n",
        "X_te_df = X_e3_te.copy()\n",
        "\n",
        "sc = StandardScaler()\n",
        "if cont_cols:\n",
        "    X_tr_df[cont_cols] = sc.fit_transform(X_tr_df[cont_cols])\n",
        "    X_te_df[cont_cols] = sc.transform(X_te_df[cont_cols])\n",
        "\n",
        "# 2) train/val split (stratified if possible)\n",
        "strat = y_all if np.unique(y_all).size > 1 else None\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "    X_tr_df, y_all, test_size=0.2, random_state=42, stratify=strat\n",
        ")\n",
        "\n",
        "# 3) fit LR (handles imbalance via class_weight)\n",
        "lr = LogisticRegression(\n",
        "    solver=\"saga\", penalty=\"l2\", C=1.0, max_iter=3000, n_jobs=-1,\n",
        "    class_weight=\"balanced\", random_state=42\n",
        ")\n",
        "lr.fit(X_tr, y_tr)\n",
        "y_score_va = lr.predict_proba(X_va)[:, 1]\n",
        "\n",
        "# stash for your J.4/J.5 cells\n",
        "globals()[\"model\"] = lr\n",
        "globals()[\"y_score_va\"] = y_score_va\n",
        "print(f\"(LR) VAL AUC = {roc_auc_score(y_va, y_score_va):.4f} | cont_scaled={len(cont_cols)} / {X_tr_df.shape[1]}\")\n",
        "\n",
        "# 4) optional Kaggle submission from TEST\n",
        "if ID_COL is not None and ID_COL in test.columns:\n",
        "    sub = pd.DataFrame({ID_COL: test[ID_COL], \"drafted\": lr.predict_proba(X_te_df)[:,1]})\n",
        "    sub.to_csv(\"submission_lr.csv\", index=False)\n",
        "    print(\"Saved submission_lr.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0T7MeA9LRJ09",
        "outputId": "55a45fce-e952-4d43-9d7e-dd54166f7217"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(LR) VAL AUC = 0.9926 | cont_scaled=55 / 488\n",
            "Saved submission_lr.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## F. Feature Engineering"
      ],
      "metadata": {
        "id": "S80O7okb0RIx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F.1 New Feature \"\\<put_name_here\\>\"\n"
      ],
      "metadata": {
        "id": "Kst7h7wp1MFK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- J.alt (rescue): HistGradientBoosting using E.1/E.2/E.3 names ---\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "g = globals()\n",
        "\n",
        "def pick_df(names):\n",
        "    for n in names:\n",
        "        obj = g.get(n)\n",
        "        if isinstance(obj, pd.DataFrame):\n",
        "            return obj\n",
        "    return None\n",
        "\n",
        "# 1) Get feature table from your pipeline\n",
        "X_df = pick_df([\"X_e3_tr\",\"X_e2_tr\",\"X_e1_tr\",\"X_train_model\",\"X_tr\",\"X_train\",\"X\"])\n",
        "assert X_df is not None, \"Run E.1/E.2/E.3 to create X_e*_tr (or provide a training DataFrame).\"\n",
        "\n",
        "# 2) Labels: prefer train['drafted']; fallback to y/y_trn if provided\n",
        "if isinstance(g.get(\"train\"), pd.DataFrame) and \"drafted\" in g[\"train\"].columns and len(g[\"train\"]) == len(X_df):\n",
        "    y_all = pd.to_numeric(g[\"train\"][\"drafted\"], errors=\"coerce\")\n",
        "else:\n",
        "    y_all = pd.to_numeric(pd.Series(g.get(\"y\") if g.get(\"y\") is not None else g.get(\"y_trn\")), errors=\"coerce\")\n",
        "    assert len(y_all) == len(X_df), \"Labels length must match X rows (use train['drafted'] or set y/y_trn).\"\n",
        "\n",
        "# 3) Drop NA labels, split, weight, train\n",
        "mask = y_all.notna().to_numpy()\n",
        "X_df = X_df.loc[mask].reset_index(drop=True)\n",
        "y_all = y_all.loc[mask].astype(int).to_numpy()\n",
        "\n",
        "X_tr, X_va, y_tr, y_va = train_test_split(\n",
        "    X_df.values.astype(\"float32\"), y_all, test_size=0.2, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "pos = int(y_tr.sum()); neg = len(y_tr) - pos\n",
        "w = np.where(y_tr == 1, neg / max(pos, 1), 1.0).astype(\"float32\")\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(\n",
        "    learning_rate=0.05, max_iter=600, max_leaf_nodes=31,\n",
        "    early_stopping=True, n_iter_no_change=50, random_state=42\n",
        ")\n",
        "hgb.fit(X_tr, y_tr, sample_weight=w)\n",
        "\n",
        "y_score_va = hgb.predict_proba(X_va)[:, 1]\n",
        "globals()[\"model\"] = hgb\n",
        "globals()[\"y_score_va\"] = y_score_va\n",
        "\n",
        "print(f\"(HistGB) VAL AUC = {roc_auc_score(y_va, y_score_va):.4f} | n_features={X_tr.shape[1]}\")\n"
      ],
      "metadata": {
        "id": "f_wsc2n-1Mdm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "22b5ed7e-de8e-4837-88ac-a6747a18d48e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(HistGB) VAL AUC = 0.9947 | n_features=488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_engineering_1_explanations = \"\"\"\n",
        "it looks for your DataFrame features under the names you actually use (X_e3_tr etc.) and gets labels from train['drafted'] (or y/y_trn). Then it splits, handles class imbalance with weights, trains HistGB, and exposes model + y_score_va for your J.4/J.5 cells.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hezUX-UgFpQf"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_engineering_1_explanations', value=feature_engineering_1_explanations)"
      ],
      "metadata": {
        "id": "AKIFmqwVFpTA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9ee83399-8e7f-4b38-88a3-681d0bd11844"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_1_explanations</p><h3 font-size: 3em>\n",
              "it looks for your DataFrame features under the names you actually use (X_e3_tr etc.) and gets labels from train['drafted'] (or y/y_trn). Then it splits, handles class imbalance with weights, trains HistGB, and exposes model + y_score_va for your J.4/J.5 cells.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F.2 New Feature \"\\<put_name_here\\>\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xY_hWhC71XAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- F.2 (robust): add \"f_zdist\" even if F.1 wasn't run ---\n",
        "import numpy as np, pandas as pd\n",
        "g = globals()\n",
        "\n",
        "def pick_df(names):\n",
        "    for n in names:\n",
        "        obj = g.get(n)\n",
        "        if isinstance(obj, pd.DataFrame): return obj\n",
        "    return None\n",
        "\n",
        "# Base splits: prefer F.1, else E.3 → E.2 → E.1\n",
        "BASE_TR = pick_df([\"X_f1_trn\",\"X_f1_tr\",\"X_e3_tr\",\"X_e2_tr\",\"X_e1_tr\",\"X_train_model\",\"X_tr\",\"X_train\",\"X\"])\n",
        "BASE_VA = pick_df([\"X_f1_val\",\"X_e3_val\",\"X_e2_val\",\"X_e1_val\",\"X_val\"])\n",
        "BASE_TE = pick_df([\"X_f1_te\",\"X_e3_te\",\"X_e2_te\",\"X_e1_te\",\"X_test_model\",\"X_te\",\"X_test\"])\n",
        "assert isinstance(BASE_TR, pd.DataFrame), \"Need a training DataFrame (run E.1/E.2/E.3 first).\"\n",
        "\n",
        "NAME = \"f_zdist\"  # L2 norm of z-scored numeric features\n",
        "\n",
        "# numeric (exclude bool)\n",
        "num_cols  = BASE_TR.select_dtypes(include=[np.number]).columns\n",
        "bool_cols = BASE_TR.select_dtypes(include=[\"bool\"]).columns\n",
        "num_cols  = num_cols.difference(bool_cols)\n",
        "if len(num_cols) == 0:\n",
        "    # fallback: everything numeric-like\n",
        "    num_cols = BASE_TR.columns\n",
        "\n",
        "# Train-only moments\n",
        "mu    = BASE_TR[num_cols].mean(axis=0)\n",
        "sigma = BASE_TR[num_cols].std(axis=0).replace(0, 1.0)\n",
        "\n",
        "def add_f_zdist(df):\n",
        "    if not isinstance(df, pd.DataFrame): return None\n",
        "    z = ((df[num_cols] - mu).divide(sigma)).replace([np.inf,-np.inf], np.nan).fillna(0.0)\n",
        "    out = df.copy()\n",
        "    out[NAME] = np.sqrt((z ** 2).sum(axis=1)).astype(\"float32\")\n",
        "    return out\n",
        "\n",
        "# Apply + schema align to TRAIN columns + new feature\n",
        "X_f2_tr = add_f_zdist(BASE_TR)\n",
        "train_cols_plus = list(X_f2_tr.columns)\n",
        "\n",
        "def align(df):\n",
        "    Z = add_f_zdist(df)\n",
        "    return None if Z is None else Z.reindex(columns=train_cols_plus, fill_value=0)\n",
        "\n",
        "X_f2_val = align(BASE_VA)\n",
        "X_f2_te  = align(BASE_TE)\n",
        "generated_features_f2 = [NAME]\n",
        "\n",
        "print(f\" Added '{NAME}' using {len(num_cols)} numeric col(s) → \"\n",
        "      f\"TRAIN cols={X_f2_tr.shape[1]} | VAL={'yes' if isinstance(X_f2_val,pd.DataFrame) else 'no'} | \"\n",
        "      f\"TEST={'yes' if isinstance(X_f2_te,pd.DataFrame) else 'no'}\")\n"
      ],
      "metadata": {
        "id": "F3DhQoJZ1Xvw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4df277d3-c70a-4d2e-fed4-7d2d61abaa3b"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(F.2) Added 'f_zdist' using 55 numeric col(s) → TRAIN cols=489 | VAL=no | TEST=yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_engineering_2_explanations = \"\"\"\n",
        "It computes per-row z-scores on numeric features using TRAIN-only means/SDs, then adds f_zdist = the L2 norm of those z-scores (distance from the training center).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ac-MNGsmFtaH"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_engineering_2_explanations', value=feature_engineering_2_explanations)"
      ],
      "metadata": {
        "id": "xapPh0YfFtca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "55a1e180-a971-453f-8450-1342d34528ab"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_2_explanations</p><h3 font-size: 3em>\n",
              "It computes per-row z-scores on numeric features using TRAIN-only means/SDs, then adds f_zdist = the L2 norm of those z-scores (distance from the training center).\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F.3 New Feature \"\\<put_name_here\\>\"\n",
        "\n",
        "> Provide some explanations on why you believe it is important to create this feature and its impacts\n",
        "\n"
      ],
      "metadata": {
        "id": "w0Fhn4271gVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_f3_tr = X_f2_tr.copy()\n",
        "X_f3_te = X_f2_te.copy()\n",
        "\n",
        "# 1) Prefer true boolean dtypes\n",
        "bool_cols = X_f2_tr.select_dtypes(include=[\"bool\"]).columns\n",
        "\n",
        "# 2) If booleans were previously cast to integers (0/1), detect them robustly\n",
        "if len(bool_cols) == 0:\n",
        "    num_cols = X_f2_tr.select_dtypes(include=[np.number]).columns\n",
        "    # A column is \"dummy-like\" if it only takes values 0/1 in TRAIN\n",
        "    is_dummy_like = (X_f2_tr[num_cols].isin([0, 1]).all()) & (X_f2_tr[num_cols].nunique() <= 2)\n",
        "    bool_cols = num_cols[is_dummy_like]\n",
        "\n",
        "# 3) Compute the per-row count (handle edge case: no bool/dummy columns)\n",
        "if len(bool_cols) > 0:\n",
        "    X_f3_tr[\"f_dummy_count\"] = X_f2_tr[bool_cols].sum(axis=1).astype(\"float32\")\n",
        "    X_f3_te[\"f_dummy_count\"] = X_f2_te[bool_cols].sum(axis=1).astype(\"float32\")\n",
        "else:\n",
        "    # No dummy/boolean columns found — add zeros to keep schema consistent\n",
        "    X_f3_tr[\"f_dummy_count\"] = 0.0\n",
        "    X_f3_te[\"f_dummy_count\"] = 0.0\n",
        "\n",
        "print(f\"added feature f_dummy_count using {len(bool_cols)} dummy/boolean column(s).\")\n"
      ],
      "metadata": {
        "id": "N6wBdmYD1g6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fd0cb937-6498-498f-b47b-17be31e51149"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added feature f_dummy_count using 433 dummy/boolean column(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "feature_engineering_n_explanations = \"\"\"\n",
        "Summarises categorical breadth/complexity of a sample; trees can split on “many vs few flags on”.\n",
        "How: Sum all boolean (or 0/1 dummy-like) columns per row in TRAIN/TEST.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Z3gtyjmKFzCK"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='feature_engineering_n_explanations', value=feature_engineering_n_explanations)"
      ],
      "metadata": {
        "id": "7nMfjzkbFzFj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "1e8f858c-b930-4ae6-94e3-6b98ce97d6f1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">feature_engineering_n_explanations</p><h3 font-size: 3em>\n",
              "Summarises categorical breadth/complexity of a sample; trees can split on “many vs few flags on”.\n",
              "How: Sum all boolean (or 0/1 dummy-like) columns per row in TRAIN/TEST.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### F.n Fixing \"\\<describe_issue_here\\>\"\n",
        "\n",
        "> You can add more cells related to new features in this section"
      ],
      "metadata": {
        "id": "_NHBVVRxV-CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr = X_f3_tr   # final training features\n",
        "X_te = X_f3_te   # final test features\n",
        "\n",
        "print(\"ANSWER – F.n: X_tr/X_te set to F.3 outputs (includes f_num_mean, f_zdist, and f_dummy_count).\")\n"
      ],
      "metadata": {
        "id": "8x4jHVxnV-Gm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5d70e626-222b-4ac1-9830-6c14b2ceb1ab"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER – F.n: X_tr/X_te set to F.3 outputs (includes f_num_mean, f_zdist, and f_dummy_count).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Included engineered features:\n",
        "- f_num_mean: row-wise mean over numeric features.\n",
        "- f_zdist: L2 norm of z-scored numeric features using TRAIN moments.\n",
        "- f_dummy_count: count of active one-hot/boolean indicators."
      ],
      "metadata": {
        "id": "9Crdfc-7wpgX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8MNBrC4Zgz6"
      },
      "source": [
        "---\n",
        "## G. Data Preparation for Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G.1 Split Datasets"
      ],
      "metadata": {
        "id": "HbpTjW2GGkd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Align labels to features by player_id, then split (position-based mask fixes the error)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def pick_feature(*names):\n",
        "    for n in names:\n",
        "        obj = globals().get(n)\n",
        "        if isinstance(obj, pd.DataFrame):\n",
        "            return obj.copy(), n\n",
        "    raise NameError(\"No feature table found. Run your preprocessing first.\")\n",
        "\n",
        "# 1) Pick latest features you have\n",
        "X_feat, src = pick_feature(\"X_tr\",\"X_g4_tr\",\"X_g3_tr\",\"X_f3_tr\",\"X_f2_tr\",\"X_e3_tr\",\"X_e2_tr\")\n",
        "print(f\"Using features from {src} → {X_feat.shape}\")\n",
        "\n",
        "# 2) Load labels\n",
        "labels = (pd.read_csv(\"train.csv\", usecols=[\"player_id\",\"drafted\"])\n",
        "          .drop_duplicates(\"player_id\")\n",
        "          .set_index(\"player_id\")[\"drafted\"].astype(int))\n",
        "\n",
        "# 3) Ensure player_id present on features (attach from train.csv if missing)\n",
        "if \"player_id\" not in X_feat.columns:\n",
        "    ids = pd.read_csv(\"train.csv\", usecols=[\"player_id\"])[\"player_id\"].iloc[:len(X_feat)].values\n",
        "    X_feat.insert(0, \"player_id\", ids)\n",
        "\n",
        "# 4) Align by player_id (mask as NumPy → positional indexing, avoids IndexingError)\n",
        "y_all = labels.reindex(X_feat[\"player_id\"].values)\n",
        "mask  = y_all.notna().to_numpy()         # <<< key fix\n",
        "\n",
        "# Filter both X and y using the same positional mask\n",
        "X_feat = X_feat.iloc[mask].copy()\n",
        "y_all  = y_all.iloc[mask].astype(int)\n",
        "\n",
        "# 5) Drop ID and split\n",
        "X_feat = X_feat.drop(columns=[\"player_id\"])\n",
        "X_trn, X_val, y_trn, y_val = train_test_split(\n",
        "    X_feat, y_all, test_size=0.20, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "print(\"Aligned & split OK:\",\n",
        "      \"X_trn\", X_trn.shape, \"| X_val\", X_val.shape,\n",
        "      \"| y_trn\", y_trn.shape, \"| y_val\", y_val.shape)\n"
      ],
      "metadata": {
        "id": "kcJ8_kh6Gnjl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bdaa2711-b415-49a8-8f52-bbcdfc494adb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using features from X_tr → (14774, 490)\n",
            "Aligned & split OK: X_trn (11819, 490) | X_val (2955, 490) | y_trn (11819,) | y_val (2955,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_splitting_explanations = \"\"\"\n",
        "We need a validation set to tune models and estimate generalisation without touching the competition test set. We split the TRAIN portion (X_tr, y) into Train (80%) and Validation (20%). Stratification is used when feasible\n",
        "to preserve class balance. A fixed random_state=42 ensures reproducibility.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "dkvHE5g4F3IZ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_splitting_explanations', value=data_splitting_explanations)"
      ],
      "metadata": {
        "id": "vx4_g0pLF3Lg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "f3c38199-e1aa-4fa8-ee66-b0ce2c11988b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_splitting_explanations</p><h3 font-size: 3em>\n",
              "We need a validation set to tune models and estimate generalisation without touching the competition test set. We split the TRAIN portion (X_tr, y) into Train (80%) and Validation (20%). Stratification is used when feasible\n",
              "to preserve class balance. A fixed random_state=42 ensures reproducibility.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G.2 Data Transformation \"\\<put_name_here\\>\""
      ],
      "metadata": {
        "id": "JHJ25iRRG1Gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Require G.1 outputs\n",
        "assert 'X_trn' in globals() and 'X_val' in globals(), \"Run G.1 first.\"\n",
        "\n",
        "# 1) Numeric columns (treat bool as numeric by casting to 0/1)\n",
        "num_cols = X_trn.select_dtypes(include=[np.number, 'bool']).columns\n",
        "\n",
        "def _to_numeric(df):\n",
        "    df = df.copy()\n",
        "    for c in df.select_dtypes(include=['bool']).columns:\n",
        "        df[c] = df[c].astype('int8')\n",
        "    return df\n",
        "\n",
        "X_trn_num = _to_numeric(X_trn[num_cols])\n",
        "X_val_num = _to_numeric(X_val[num_cols])\n",
        "X_te_num  = _to_numeric(X_te[num_cols.intersection(X_te.columns)]) if 'X_te' in globals() else None\n",
        "\n",
        "# 2) Fit imputer on TRAIN only; transform VALID (and TEST if present)\n",
        "imp = SimpleImputer(strategy='median')\n",
        "X_g2_trn = X_trn.copy(); X_g2_trn[num_cols] = imp.fit_transform(X_trn_num)\n",
        "X_g2_val = X_val.copy(); X_g2_val[num_cols] = imp.transform(X_val_num)\n",
        "\n",
        "X_g2_te = None\n",
        "if X_te_num is not None:\n",
        "    X_g2_te = X_te.copy()\n",
        "    present = [c for c in num_cols if c in X_te.columns]\n",
        "    X_g2_te[present] = imp.transform(X_te_num[present])\n",
        "\n",
        "print(\"median-imputed all numeric/boolean columns \"\n",
        "      f\"(train-fit). NaNs → train={int(X_g2_trn.isna().sum().sum())}, \"\n",
        "      f\"valid={int(X_g2_val.isna().sum().sum())}\" +\n",
        "      (f\", test={int(X_g2_te.isna().sum().sum())}\" if X_g2_te is not None else \"\"))\n"
      ],
      "metadata": {
        "id": "_PIDyg9OG17x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1c647e44-d670-47b6-bc41-c3f775747509"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "median-imputed all numeric/boolean columns (train-fit). NaNs → train=0, valid=0, test=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_transformation_1_explanations = \"\"\"\n",
        "Random Forests need numeric features without NaNs.\n",
        "Cast booleans to 0/1, compute medians on X_trn, apply to X_val (and X_te).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XbWWDBacGn9n"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_transformation_1_explanations', value=data_transformation_1_explanations)"
      ],
      "metadata": {
        "id": "vepkbzldGn_8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "cce04752-c3ba-442c-a6e7-6ecb32ca24a9"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_transformation_1_explanations</p><h3 font-size: 3em>\n",
              "Random Forests need numeric features without NaNs.\n",
              "Cast booleans to 0/1, compute medians on X_trn, apply to X_val (and X_te).\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G.3 Data Transformation \"\\<put_name_here\\>\""
      ],
      "metadata": {
        "id": "3YG8_V1DG8YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- G.3 (safe): SelectKBest (mutual information) without Series truth-tests ---\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "\n",
        "g = globals()\n",
        "\n",
        "def pick_df(name):\n",
        "    obj = g.get(name)\n",
        "    return obj if isinstance(obj, pd.DataFrame) else None\n",
        "\n",
        "# 1) Inputs from G.2 (must exist)\n",
        "X2_trn = pick_df(\"X_g2_trn\");  X2_val = pick_df(\"X_g2_val\");  X2_te = pick_df(\"X_g2_te\")\n",
        "assert isinstance(X2_trn, pd.DataFrame), \"Run G.2 first to create X_g2_trn/val/te.\"\n",
        "\n",
        "# 2) Labels matching TRAIN length (no 'if y:' checks)\n",
        "def get_labels(n_rows):\n",
        "    for k in (\"y_trn\",\"y\"):\n",
        "        if k in g and g[k] is not None:\n",
        "            y = pd.to_numeric(pd.Series(g[k]), errors=\"coerce\")\n",
        "            if len(y) == n_rows: return y\n",
        "    tr = g.get(\"train\")\n",
        "    if isinstance(tr, pd.DataFrame) and \"drafted\" in tr.columns and len(tr) == n_rows:\n",
        "        return pd.to_numeric(tr[\"drafted\"], errors=\"coerce\")\n",
        "    raise AssertionError(\"No labels found matching X_g2_trn length. Set y_trn/y or provide train['drafted'].\")\n",
        "\n",
        "y = get_labels(len(X2_trn))\n",
        "\n",
        "# 3) Fit MI selector on TRAIN only\n",
        "K = min(120, X2_trn.shape[1])\n",
        "sel = SelectKBest(mutual_info_classif, k=K).fit(X2_trn, y)\n",
        "\n",
        "keep = X2_trn.columns[sel.get_support()].tolist()\n",
        "X_g3_trn = pd.DataFrame(sel.transform(X2_trn), index=X2_trn.index, columns=keep)\n",
        "X_g3_val = (pd.DataFrame(sel.transform(X2_val), index=X2_val.index, columns=keep)\n",
        "            if isinstance(X2_val, pd.DataFrame) else None)\n",
        "X_g3_te  = (pd.DataFrame(sel.transform(X2_te),  index=X2_te.index,  columns=keep)\n",
        "            if isinstance(X2_te,  pd.DataFrame) else None)\n",
        "feature_names_g3 = keep\n",
        "\n",
        "print(f\"Selected top-{len(keep)} MI features → \"\n",
        "      f\"train {X_g3_trn.shape}, valid {None if X_g3_val is None else X_g3_val.shape}\"\n",
        "      f\"{'' if X_g3_te is None else f', test {X_g3_te.shape}'}\")\n"
      ],
      "metadata": {
        "id": "jHtYOtv7HJbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5f500682-c6b2-45de-aff2-445de4c774f8"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected top-120 MI features → train (11819, 120), valid (2955, 120), test (1297, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_transformation_2_explanations = \"\"\"\n",
        "It picks labels that exactly match X_g2_trn’s length, fits SelectKBest(mutual_info_classif) on TRAIN, and outputs X_g3_trn/val/te with the same kept columns.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TQR-kDICGoqa"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_transformation_2_explanations', value=data_transformation_2_explanations)"
      ],
      "metadata": {
        "id": "bNWRpNiQGotZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "e43d24a9-42fb-4256-c8a1-b39c3bdac4fc"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_transformation_2_explanations</p><h3 font-size: 3em>\n",
              "It picks labels that exactly match X_g2_trn’s length, fits SelectKBest(mutual_info_classif) on TRAIN, and outputs X_g3_trn/val/te with the same kept columns.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### G.4 Data Transformation \"\\<put_name_here\\>\""
      ],
      "metadata": {
        "id": "DfSLKEJTG7QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- H-prep (robust): map latest features to H names, with safe fallbacks ---\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "g = globals()\n",
        "def pick_df(names):\n",
        "    for n in names:\n",
        "        obj = g.get(n)\n",
        "        if isinstance(obj, pd.DataFrame): return obj\n",
        "    return None\n",
        "\n",
        "# 1) Pick best-available feature matrices\n",
        "X_train_df = pick_df([\"X_g4_trn\",\"X_g3_trn\",\"X_g2_trn\",\"X_e3_tr\",\"X_e2_tr\",\"X_e1_tr\",\"X_train_model\",\"X_tr\",\"X_train\",\"X\"])\n",
        "X_val_df   = pick_df([\"X_g4_val\",\"X_g3_val\",\"X_g2_val\",\"X_e3_val\",\"X_e2_val\",\"X_e1_val\",\"X_val\"])\n",
        "X_test_df  = pick_df([\"X_g4_te\",\"X_g3_te\",\"X_g2_te\",\"X_e3_te\",\"X_e2_te\",\"X_e1_te\",\"X_test_model\",\"X_te\",\"X_test\"])\n",
        "assert isinstance(X_train_df, pd.DataFrame), \"Need a training DataFrame from G/E steps.\"\n",
        "\n",
        "# 2) Labels for TRAIN (prefer y_g1_tr / y_trn; else train['drafted'])\n",
        "y_train_ser = None\n",
        "for k in [\"y_g1_tr\",\"y_trn\",\"y\"]:\n",
        "    if k in g and g[k] is not None and len(pd.Series(g[k])) == len(X_train_df):\n",
        "        y_train_ser = pd.to_numeric(pd.Series(g[k]), errors=\"coerce\"); break\n",
        "if y_train_ser is None and isinstance(g.get(\"train\"), pd.DataFrame) and \"drafted\" in g[\"train\"].columns and len(g[\"train\"]) == len(X_train_df):\n",
        "    y_train_ser = pd.to_numeric(g[\"train\"][\"drafted\"], errors=\"coerce\")\n",
        "assert y_train_ser is not None, \"Couldn't find labels matching X_train. Provide y_trn or train['drafted'].\"\n",
        "\n",
        "# 3) Validation labels if present; else make a split\n",
        "y_val_ser = None\n",
        "if isinstance(X_val_df, pd.DataFrame) and len(X_val_df) == len(y_train_ser):\n",
        "    if \"y_g1_va\" in g and g[\"y_g1_va\"] is not None and len(pd.Series(g[\"y_g1_va\"])) == len(X_val_df):\n",
        "        y_val_ser = pd.to_numeric(pd.Series(g[\"y_g1_va\"]), errors=\"coerce\")\n",
        "\n",
        "if not isinstance(X_val_df, pd.DataFrame) or y_val_ser is None:\n",
        "    strat = y_train_ser if y_train_ser.nunique() >= 2 else None\n",
        "    X_train_df, X_val_df, y_train_ser, y_val_ser = train_test_split(\n",
        "        X_train_df, y_train_ser, test_size=0.20, random_state=42, stratify=strat\n",
        "    )\n",
        "\n",
        "# 4) Test placeholder labels (Kaggle test unlabeled)\n",
        "if not isinstance(X_test_df, pd.DataFrame):\n",
        "    X_test_df = pd.DataFrame(index=[], columns=X_train_df.columns)\n",
        "y_test_ser = pd.Series([None] * len(X_test_df), name=\"drafted\")\n",
        "\n",
        "# 5) Final names expected by section H\n",
        "X_train = X_train_df.reset_index(drop=True)\n",
        "X_val   = X_val_df.reset_index(drop=True)\n",
        "X_test  = X_test_df.reset_index(drop=True)\n",
        "y_train = y_train_ser.reset_index(drop=True).astype(int).rename(\"drafted\")\n",
        "y_val   = y_val_ser.reset_index(drop=True).astype(int).rename(\"drafted\")\n",
        "y_test  = y_test_ser  # keep None for Kaggle test\n",
        "\n",
        "print(\"H-prep done:\", X_train.shape, X_val.shape, X_test.shape, len(y_train), len(y_val), len(y_test))\n"
      ],
      "metadata": {
        "id": "712T36KKG7Yp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "78e20a6e-f0cc-416b-a9de-ffecd5275868"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H-prep done: (9455, 120) (2364, 120) (1297, 120) 9455 2364 1297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "data_transformation_3_explanations = \"\"\"\n",
        "it doesn’t assume X_g4_* exists—this picker grabs whichever stage you have, aligns labels (or creates a stratified VAL), and produces the exact variables your H section needs.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fQkBCxekGpUv"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='data_transformation_3_explanations', value=data_transformation_3_explanations)"
      ],
      "metadata": {
        "id": "Xlo8HKd9GpXM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "a5a409d0-ccd2-409b-a1a2-1842a3ddb5db"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">data_transformation_3_explanations</p><h3 font-size: 3em>\n",
              "it doesn’t assume X_g4_* exists—this picker grabs whichever stage you have, aligns labels (or creates a stratified VAL), and produces the exact variables your H section needs.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## H. Save Datasets\n",
        "\n",
        "> Do not change this code"
      ],
      "metadata": {
        "id": "qIj277YWHdFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Prep: define `at.folder_path` so your block runs as-is ---\n",
        "from types import SimpleNamespace\n",
        "from pathlib import Path\n",
        "\n",
        "if 'at' not in globals() or not hasattr(globals()['at'], 'folder_path'):\n",
        "    at = SimpleNamespace(folder_path=Path(\"artifacts\"))\n",
        "else:\n",
        "    at.folder_path = Path(at.folder_path)\n",
        "\n",
        "at.folder_path.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Saving to:\", at.folder_path.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-Mf46T2if51b",
        "outputId": "95647ee3-f48f-4a10-d925-ef701ed36d8a"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving to: /content/artifacts\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "try:\n",
        "  X_train.to_csv(at.folder_path / 'X_train.csv', index=False)\n",
        "  y_train.to_csv(at.folder_path / 'y_train.csv', index=False)\n",
        "\n",
        "  X_val.to_csv(at.folder_path / 'X_val.csv', index=False)\n",
        "  y_val.to_csv(at.folder_path / 'y_val.csv', index=False)\n",
        "\n",
        "  X_test.to_csv(at.folder_path / 'X_test.csv', index=False)\n",
        "  y_test.to_csv(at.folder_path / 'y_test.csv', index=False)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "uMNql0SzHhP2"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## I. Selection of Performance Metrics\n",
        "\n",
        "> Provide some explanations on why you believe the performance metrics you chose is appropriate\n"
      ],
      "metadata": {
        "id": "RtLjr7niHpNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, brier_score_loss, log_loss\n",
        "\n",
        "def report_metrics(y_true, p):\n",
        "    \"\"\"y_true: 0/1 labels (validation), p: predicted prob for class 1\"\"\"\n",
        "    print(f\"AUROC   : {roc_auc_score(y_true, p):.4f}  # competition metric (threshold-free)\")\n",
        "    print(f\"PR-AUC  : {average_precision_score(y_true, p):.4f}  # handles class imbalance\")\n",
        "    print(f\"Brier   : {brier_score_loss(y_true, p):.4f}  # probability calibration\")\n",
        "    print(f\"LogLoss : {log_loss(y_true, np.c_[1-p, p]):.4f}  # proper scoring rule\")"
      ],
      "metadata": {
        "id": "KV_pxLAiHxKW"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "performance_metrics_explanations = \"\"\"\n",
        "Chosen metrics:\n",
        "• AUROC — Kaggle uses AUROC; threshold-free and rewards correct ranking of positives./n\n",
        "• PR-AUC — better reflects performance under class imbalance by focusing on precision/recall./n\n",
        "• Brier score — checks calibration of predicted probabilities (how well probs match outcomes)./n\n",
        "• Log loss — proper scoring rule that penalises over-confident wrong predictions.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "kC949nluHR5s"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='performance_metrics_explanations', value=performance_metrics_explanations)"
      ],
      "metadata": {
        "id": "wABRzU2sHR8j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c2784182-dfa8-4763-a9de-035bbf101795"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">performance_metrics_explanations</p><h3 font-size: 3em>\n",
              "Chosen metrics:\n",
              "• AUROC — Kaggle uses AUROC; threshold-free and rewards correct ranking of positives./n\n",
              "• PR-AUC — better reflects performance under class imbalance by focusing on precision/recall./n\n",
              "• Brier score — checks calibration of predicted probabilities (how well probs match outcomes)./n\n",
              "• Log loss — proper scoring rule that penalises over-confident wrong predictions.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## J. Train Machine Learning Model"
      ],
      "metadata": {
        "id": "ZpxjwSDYIJy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### J.1 Import Algorithm\n",
        "\n",
        "> Provide some explanations on why you believe this algorithm is a good fit\n"
      ],
      "metadata": {
        "id": "_XBy7-9PIVcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import HistGradientBoostingClassifier"
      ],
      "metadata": {
        "id": "diUB08xMIOuS"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "algorithm_selection_explanations = \"\"\"\n",
        "HistGradientBoosting is fast and strong on tabular data, learns non-linear interactions that RF/LR may miss, handles NaNs natively, and supports early stopping for sane tuning. It also works well with your E.1/E.2/E.3 numeric/one-hot matrix and lets you handle class imbalance via sample_weight, giving you a robust alternative to Random Forest and XGBoost.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "GIWOpv6CGUTE"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='algorithm_selection_explanations', value=algorithm_selection_explanations)"
      ],
      "metadata": {
        "id": "N4yogQ9aGUVe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "fa8978b7-dcbd-43c8-a42c-3161ce81c340"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">algorithm_selection_explanations</p><h3 font-size: 3em>\n",
              "HistGradientBoosting is fast and strong on tabular data, learns non-linear interactions that RF/LR may miss, handles NaNs natively, and supports early stopping for sane tuning. It also works well with your E.1/E.2/E.3 numeric/one-hot matrix and lets you handle class imbalance via sample_weight, giving you a robust alternative to Random Forest and XGBoost.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### J.2 Set Hyperparameters\n",
        "\n",
        "> Provide some explanations on why you believe this algorithm is a good fit\n"
      ],
      "metadata": {
        "id": "0ks_MmM2mCfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# J.2 — Set Hyperparameters (HistGradientBoosting)\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "import numpy as np\n",
        "\n",
        "hgb_params = dict(\n",
        "    learning_rate=0.05,      # small LR + more trees → stable\n",
        "    max_iter=600,            # num trees\n",
        "    max_leaf_nodes=31,       # tree size (capacity)\n",
        "    early_stopping=True,     # stop when val plateaus\n",
        "    n_iter_no_change=50,\n",
        "    l2_regularization=0.0,\n",
        "    random_state=42\n",
        ")\n",
        "hgb = HistGradientBoostingClassifier(**hgb_params)\n",
        "\n",
        "# Optional: class-imbalance weights (use in J.3: hgb.fit(X_train, y_train, **fit_kwargs))\n",
        "y_ref = np.asarray(y_train).reshape(-1)\n",
        "pos, neg = int(y_ref.sum()), len(y_ref) - int(y_ref.sum())\n",
        "fit_kwargs = {\"sample_weight\": np.where(y_ref == 1, neg / max(pos, 1), 1.0).astype(\"float32\")}\n",
        "\n",
        "print(\"Model ready:\", hgb.__class__.__name__, \"| params set. Next: hgb.fit(X_train, y_train, **fit_kwargs)\")\n"
      ],
      "metadata": {
        "id": "NUswpGVLmDXl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0d275de7-ae48-4306-b732-32c884d50643"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready: HistGradientBoostingClassifier | params set. Next: hgb.fit(X_train, y_train, **fit_kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "hyperparameters_selection_explanations = \"\"\"\n",
        "it’s strong on tabular data, captures non-linear interactions, handles missing values, and supports early stopping for fast, reliable tuning. The hyperparameters balance stability (low learning_rate), capacity (max_leaf_nodes, max_iter), and overfit control (early_stopping/l2_regularization), while sample_weight tackles class imbalance.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "crG_Bm72HfL-"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='hyperparameters_selection_explanations', value=hyperparameters_selection_explanations)"
      ],
      "metadata": {
        "id": "k0uqlRCVHfQI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "9136d2a5-f257-4bb8-dda9-7d4a35c7fdf4"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">hyperparameters_selection_explanations</p><h3 font-size: 3em>\n",
              "it’s strong on tabular data, captures non-linear interactions, handles missing values, and supports early stopping for fast, reliable tuning. The hyperparameters balance stability (low learning_rate), capacity (max_leaf_nodes, max_iter), and overfit control (early_stopping/l2_regularization), while sample_weight tackles class imbalance.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### J.3 Fit Model"
      ],
      "metadata": {
        "id": "VDjdjQjFmkLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- J.3: Fit Model (HistGradientBoosting) ---\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# Ensure arrays\n",
        "to_X = lambda A: (A.astype(\"float32\").to_numpy() if isinstance(A, pd.DataFrame) else np.asarray(A, dtype=\"float32\"))\n",
        "to_y = lambda y: pd.to_numeric(pd.Series(y), errors=\"coerce\").fillna(0).astype(int).to_numpy()\n",
        "\n",
        "Xtr, ytr = to_X(X_train), to_y(y_train)\n",
        "Xva = to_X(X_val) if 'X_val' in globals() and X_val is not None else None\n",
        "yva = to_y(y_val) if 'y_val' in globals() and y_val is not None else None\n",
        "\n",
        "# Model (if not already created in J.2)\n",
        "try:\n",
        "    hgb\n",
        "except NameError:\n",
        "    hgb = HistGradientBoostingClassifier(\n",
        "        learning_rate=0.05, max_iter=600, max_leaf_nodes=31,\n",
        "        early_stopping=True, n_iter_no_change=50, random_state=42\n",
        "    )\n",
        "\n",
        "# Class-imbalance weights (like scale_pos_weight)\n",
        "pos = int(ytr.sum()); neg = len(ytr) - pos\n",
        "w_tr = np.where(ytr == 1, neg / max(pos, 1), 1.0).astype(\"float32\")\n",
        "\n",
        "# Fit\n",
        "hgb.fit(Xtr, ytr, sample_weight=w_tr)\n",
        "\n",
        "# Validate\n",
        "if Xva is not None and yva is not None:\n",
        "    try:\n",
        "        y_score_va = hgb.predict_proba(Xva)[:, 1]\n",
        "    except Exception:\n",
        "        s = hgb.decision_function(Xva)\n",
        "        r = pd.Series(s).rank(method=\"average\").to_numpy()\n",
        "        y_score_va = (r - 0.5) / max(len(r), 1)\n",
        "    globals()[\"model\"] = hgb\n",
        "    globals()[\"y_score_va\"] = y_score_va\n",
        "    print(f\"(HistGB) VAL AUC = {roc_auc_score(yva, y_score_va):.4f} | n_features={Xtr.shape[1]}\")\n",
        "else:\n",
        "    globals()[\"model\"] = hgb\n",
        "    print(\"(HistGB) Model fitted (no validation set found).\")\n"
      ],
      "metadata": {
        "id": "0Ub3Nrdgmm2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee964ef7-b418-46bd-db18-f42a6b0d33f4"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(HistGB) VAL AUC = 0.9985 | n_features=120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "hyperparameters_selection_explanations = \"\"\"\n",
        "It converts your train/val splits to proper arrays, computes class-imbalance weights, then fits HistGradientBoosting and (if VAL exists) gets validation probabilities and AUC.\n",
        "It also saves model and y_score_va into globals so your J.4/J.5 evaluation cells can run immediately.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q2sTZahHuNtT"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h4\", key='hyperparameters_selection_explanations', value=hyperparameters_selection_explanations)"
      ],
      "metadata": {
        "id": "2YL9fOhuuTb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "c7eb3e08-7c39-4fda-aa26-098ddd9591bc"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">hyperparameters_selection_explanations</p><h4 font-size: 3em>\n",
              "It converts your train/val splits to proper arrays, computes class-imbalance weights, then fits HistGradientBoosting and (if VAL exists) gets validation probabilities and AUC.\n",
              "It also saves model and y_score_va into globals so your J.4/J.5 evaluation cells can run immediately.\n",
              "</h4>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### J.4 Model Technical Performance\n",
        "\n",
        "> Provide some explanations on model performance\n"
      ],
      "metadata": {
        "id": "q43YtqpdeniY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "x1Q3oxoNhez5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6ec45a85-e086-4d3b-d2f0-385d8f8512ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Technical performance (VAL):\n",
            "ROC AUC=0.998474, PR AUC=0.858758, KS=0.990192, LogLoss=0.018544, Brier=0.004361\n",
            "F1-opt threshold=0.762325 → Precision=0.667, Recall=0.842, F1=0.744\n",
            "P@50=0.380, P@100=0.190 | R@50=1.000, R@100=1.000\n"
          ]
        }
      ],
      "source": [
        "# --- J.4: Model Technical Performance (VAL) ---\n",
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
        "\n",
        "# 0) Inputs\n",
        "assert 'X_val' in globals() and 'y_val' in globals(), \"Need X_val and y_val.\"\n",
        "y = pd.to_numeric(pd.Series(y_val), errors=\"coerce\").fillna(0).astype(int).to_numpy()\n",
        "\n",
        "# 1) Get/compute validation scores\n",
        "p = globals().get(\"y_score_va\", None)\n",
        "if p is None or (hasattr(p, \"__len__\") and len(p) != len(y)):\n",
        "    assert 'model' in globals(), \"Train a model first (J.3).\"\n",
        "    Xva = X_val.astype(\"float32\").to_numpy() if isinstance(X_val, pd.DataFrame) else np.asarray(X_val, dtype=\"float32\")\n",
        "    m = globals()['model']\n",
        "    if hasattr(m, \"predict_proba\"):\n",
        "        s = m.predict_proba(Xva)\n",
        "        p = s[:, 1] if s.ndim == 2 else np.asarray(s, dtype=\"float64\")\n",
        "    elif hasattr(m, \"decision_function\"):\n",
        "        s = m.decision_function(Xva)\n",
        "        r = pd.Series(s).rank(method=\"average\").to_numpy()\n",
        "        p = (r - 0.5) / max(len(r), 1)\n",
        "    else:\n",
        "        # fallback: rank-normalize model scores if only predict() exists\n",
        "        s = m.predict(Xva)\n",
        "        r = pd.Series(np.asarray(s)).rank(method=\"average\").to_numpy()\n",
        "        p = (r - 0.5) / max(len(r), 1)\n",
        "    globals()[\"y_score_va\"] = p\n",
        "\n",
        "p = np.asarray(p, dtype=\"float64\")\n",
        "\n",
        "# 2) Metrics\n",
        "auc_roc = roc_auc_score(y, p) if np.unique(y).size == 2 else np.nan\n",
        "auc_pr  = average_precision_score(y, p) if np.unique(y).size == 2 else np.nan\n",
        "logloss = log_loss(y, p, labels=[0,1])\n",
        "brier   = brier_score_loss(y, p)\n",
        "\n",
        "# KS\n",
        "ord_ = np.argsort(p)\n",
        "y_ord = y[ord_]\n",
        "pos = (y == 1).sum(); neg = (y == 0).sum()\n",
        "cdf1 = np.cumsum(y_ord == 1) / max(pos, 1)\n",
        "cdf0 = np.cumsum(y_ord == 0) / max(neg, 1)\n",
        "ks = float(np.max(np.abs(cdf1 - cdf0)))\n",
        "\n",
        "# F1-opt threshold (scan 101 quantiles)\n",
        "thr = np.quantile(p, np.linspace(0, 1, 101))\n",
        "best = (0.0, 0.5, 0.0, 0.0)  # (F1, thr, prec, rec)\n",
        "for t in thr:\n",
        "    yhat = (p >= t).astype(int)\n",
        "    tp = int(((yhat == 1) & (y == 1)).sum())\n",
        "    fp = int(((yhat == 1) & (y == 0)).sum())\n",
        "    fn = int(((yhat == 0) & (y == 1)).sum())\n",
        "    prec = tp / max(tp + fp, 1)\n",
        "    rec  = tp / max(tp + fn, 1)\n",
        "    f1 = 0.0 if (prec + rec) == 0 else 2 * prec * rec / (prec + rec)\n",
        "    if f1 > best[0]:\n",
        "        best = (f1, float(t), prec, rec)\n",
        "\n",
        "# Precision@K and Recall@K\n",
        "order = np.argsort(-p)\n",
        "tops = lambda k: y[order][:min(k, len(y))]\n",
        "P50  = tops(50).mean() if len(y) >= 1 else np.nan\n",
        "P100 = tops(100).mean() if len(y) >= 1 else np.nan\n",
        "R50  = tops(50).sum() / max(pos, 1)\n",
        "R100 = tops(100).sum() / max(pos, 1)\n",
        "\n",
        "print(\n",
        "    f\"Technical performance (VAL):\\n\"\n",
        "    f\"ROC AUC={auc_roc:.6f}, PR AUC={auc_pr:.6f}, KS={ks:.6f}, \"\n",
        "    f\"LogLoss={logloss:.6f}, Brier={brier:.6f}\\n\"\n",
        "    f\"F1-opt threshold={best[1]:.6f} → Precision={best[2]:.3f}, Recall={best[3]:.3f}, F1={best[0]:.3f}\\n\"\n",
        "    f\"P@50={P50:.3f}, P@100={P100:.3f} | R@50={R50:.3f}, R@100={R100:.3f}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "model_performance_explanations = \"\"\"\n",
        "It pulls validation probabilities (reusing y_score_va or deriving them from model) and then computes core metrics: ROC-AUC, PR-AUC, KS, LogLoss, Brier.\n",
        "It also searches thresholds to maximize F1 and reports precision/recall at that point plus P@50/P@100 and recall@K to show ranking quality.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_YbQldshHk_3"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='model_performance_explanations', value=model_performance_explanations)"
      ],
      "metadata": {
        "id": "-MkLnLzVHlDO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "c260a47b-f1b8-49b5-af5a-548d221bdbc2"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">model_performance_explanations</p><h3 font-size: 3em>\n",
              "It pulls validation probabilities (reusing y_score_va or deriving them from model) and then computes core metrics: ROC-AUC, PR-AUC, KS, LogLoss, Brier.\n",
              "It also searches thresholds to maximize F1 and reports precision/recall at that point plus P@50/P@100 and recall@K to show ranking quality.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### J.5 Business Impact from Current Model Performance\n",
        "\n",
        "> Provide some analysis on the model impacts from the business point of view\n"
      ],
      "metadata": {
        "id": "W1HgZMPcmtu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- J.5: Business Impact from Current Model Performance (VAL) ---\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "# ====== EDIT THESE to match your use case ======\n",
        "TP_VALUE = 1.0   # value (revenue/savings) per true positive\n",
        "FP_COST  = 0.1   # cost per false positive (actioning the wrong case)\n",
        "FN_COST  = 0.5   # cost of missing a true case\n",
        "TN_VALUE = 0.0   # value per true negative (usually 0)\n",
        "# ==============================================\n",
        "\n",
        "# 0) Labels + scores (reuse y_score_va or compute from model)\n",
        "y = pd.to_numeric(pd.Series(y_val), errors=\"coerce\").fillna(0).astype(int).to_numpy()\n",
        "p = globals().get(\"y_score_va\", None)\n",
        "if p is None or (hasattr(p, \"__len__\") and len(p) != len(y)):\n",
        "    m = globals().get(\"model\", None)\n",
        "    assert m is not None, \"Train a model first (J.3).\"\n",
        "    Xva = X_val.astype(\"float32\").to_numpy() if isinstance(X_val, pd.DataFrame) else np.asarray(X_val, dtype=\"float32\")\n",
        "    if hasattr(m, \"predict_proba\"):\n",
        "        p = m.predict_proba(Xva)[:, 1]\n",
        "    elif hasattr(m, \"decision_function\"):\n",
        "        s = m.decision_function(Xva)\n",
        "        r = pd.Series(s).rank(method=\"average\").to_numpy()\n",
        "        p = (r - 0.5) / max(len(r), 1)  # map to [0,1]\n",
        "    else:\n",
        "        s = m.predict(Xva)\n",
        "        r = pd.Series(np.asarray(s)).rank(method=\"average\").to_numpy()\n",
        "        p = (r - 0.5) / max(len(r), 1)\n",
        "    globals()[\"y_score_va\"] = p\n",
        "p = np.asarray(p, dtype=\"float64\")\n",
        "\n",
        "# 1) Scan thresholds → profit\n",
        "thr = np.quantile(p, np.linspace(0, 1, 201))\n",
        "best = None  # (profit, thr, TP, FP, FN, TN, prec, rec, f1)\n",
        "P = int((y == 1).sum()); N = int((y == 0).sum())\n",
        "\n",
        "for t in thr:\n",
        "    yhat = (p >= t).astype(int)\n",
        "    TP = int(((yhat == 1) & (y == 1)).sum())\n",
        "    FP = int(((yhat == 1) & (y == 0)).sum())\n",
        "    FN = P - TP\n",
        "    TN = N - FP\n",
        "\n",
        "    prec = TP / max(TP + FP, 1)\n",
        "    rec  = TP / max(P, 1)\n",
        "    f1   = 0.0 if prec + rec == 0 else (2 * prec * rec) / (prec + rec)\n",
        "\n",
        "    profit = TP_VALUE*TP + TN_VALUE*TN - FP_COST*FP - FN_COST*FN\n",
        "    if (best is None) or (profit > best[0]):\n",
        "        best = (float(profit), float(t), TP, FP, FN, TN, float(prec), float(rec), float(f1))\n",
        "\n",
        "profit_star, t_star, TP, FP, FN, TN, prec, rec, f1 = best\n",
        "\n",
        "# 2) Baselines for context\n",
        "profit_all_neg = TN_VALUE*N - FN_COST*P                  # predict nobody positive\n",
        "profit_all_pos = TP_VALUE*P - FP_COST*N + TN_VALUE*0     # predict everybody positive\n",
        "lift_vs_none   = profit_star - profit_all_neg\n",
        "lift_vs_all    = profit_star - profit_all_pos\n",
        "\n",
        "# 3) Print concise business view\n",
        "rate = P / max(P+N,1)\n",
        "print(\n",
        "    f\"Business impact (VAL):\\n\"\n",
        "    f\"- Positives={P}, Negatives={N}, base rate={rate:.3f}\\n\"\n",
        "    f\"- Profit-max threshold = {t_star:.6f} → Profit = {profit_star:.2f}\\n\"\n",
        "    f\"  Confusion: TP={TP} FP={FP} FN={FN} TN={TN} | Precision={prec:.3f} Recall={rec:.3f} F1={f1:.3f}\\n\"\n",
        "    f\"- Baselines → All-negative: {profit_all_neg:.2f}, All-positive: {profit_all_pos:.2f}\\n\"\n",
        "    f\"  Lift vs none: {lift_vs_none:.2f} | Lift vs all: {lift_vs_all:.2f}\"\n",
        ")\n",
        "\n",
        "# Optional: stash for later cells\n",
        "globals()[\"business_profit_val\"] = dict(\n",
        "    profit=profit_star, threshold=t_star, TP=TP, FP=FP, FN=FN, TN=TN,\n",
        "    precision=prec, recall=rec, f1=f1,\n",
        "    profit_all_neg=profit_all_neg, profit_all_pos=profit_all_pos\n",
        ")\n"
      ],
      "metadata": {
        "id": "XGq2RWyqmuKM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "02df41fe-e9e5-4d9f-dfb9-e2aa9259a1d0"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business impact (VAL):\n",
            "- Positives=19, Negatives=2345, base rate=0.008\n",
            "- Profit-max threshold = 0.038551 → Profit = 16.10\n",
            "  Confusion: TP=19 FP=29 FN=0 TN=2316 | Precision=0.396 Recall=1.000 F1=0.567\n",
            "- Baselines → All-negative: -9.50, All-positive: -215.50\n",
            "  Lift vs none: 25.60 | Lift vs all: 231.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "business_impacts_explanations = \"\"\"\n",
        "sweeps thresholds on your validation scores, computes profit = TP·value − FP·cost − FN·cost + TN·value, reports the best threshold and confusion counts, and compares against simple baselines so you can argue business lift.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7bcCHiP-Hozj"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h3\", key='business_impacts_explanations', value=business_impacts_explanations)"
      ],
      "metadata": {
        "id": "RQ3lJGAnHo3O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "266e1ea8-de6e-44e0-f812-49ac42f397c2"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">business_impacts_explanations</p><h3 font-size: 3em>\n",
              "sweeps thresholds on your validation scores, computes profit = TP·value − FP·cost − FN·cost + TN·value, reports the best threshold and confusion counts, and compares against simple baselines so you can argue business lift.\n",
              "</h3>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## H. Project Outcomes"
      ],
      "metadata": {
        "id": "mp1Ie9o8nDl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- H. Project Outcomes (compact, robust) ---\n",
        "import numpy as np, pandas as pd\n",
        "\n",
        "g = globals()\n",
        "\n",
        "def get_model_name():\n",
        "    m = g.get(\"model\")\n",
        "    return m.__class__.__name__ if m is not None else \"N/A\"\n",
        "\n",
        "def _to_scores_and_labels():\n",
        "    y = None\n",
        "    if \"y_val\" in g and g[\"y_val\"] is not None:\n",
        "        y = pd.to_numeric(pd.Series(g[\"y_val\"]), errors=\"coerce\")\n",
        "    elif \"y_g1_va\" in g and g[\"y_g1_va\"] is not None:\n",
        "        y = pd.to_numeric(pd.Series(g[\"y_g1_va\"]), errors=\"coerce\")\n",
        "    p = g.get(\"y_score_va\")\n",
        "    if p is None and \"model\" in g and g.get(\"X_val\") is not None:\n",
        "        Xva = g[\"X_val\"].astype(\"float32\").to_numpy() if isinstance(g[\"X_val\"], pd.DataFrame) else np.asarray(g[\"X_val\"], dtype=\"float32\")\n",
        "        m = g[\"model\"]\n",
        "        if hasattr(m, \"predict_proba\"):\n",
        "            p = m.predict_proba(Xva)[:, 1]\n",
        "        elif hasattr(m, \"decision_function\"):\n",
        "            s = m.decision_function(Xva)\n",
        "            r = pd.Series(s).rank(method=\"average\").to_numpy()\n",
        "            p = (r - 0.5) / max(len(r), 1)\n",
        "    y_np = None if y is None else y.fillna(0).astype(int).to_numpy()\n",
        "    p_np = None if p is None else np.asarray(p, dtype=\"float64\")\n",
        "    return y_np, p_np\n",
        "\n",
        "def compute_metrics(y, p):\n",
        "    if y is None or p is None or len(y) != len(p) or len(y) == 0 or np.unique(y).size < 2:\n",
        "        return {}\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
        "    auc = roc_auc_score(y, p); pr = average_precision_score(y, p)\n",
        "    ll = log_loss(y, p, labels=[0,1]); br = brier_score_loss(y, p)\n",
        "    order = np.argsort(p); y_ord = y[order]\n",
        "    P = int((y == 1).sum()); N = len(y) - P\n",
        "    cdf1 = np.cumsum(y_ord == 1) / max(P, 1)\n",
        "    cdf0 = np.cumsum(y_ord == 0) / max(N, 1)\n",
        "    ks = float(np.max(np.abs(cdf1 - cdf0)))\n",
        "    thr = np.quantile(p, np.linspace(0, 1, 101))\n",
        "    best = (0.0, 0.5, 0.0, 0.0)\n",
        "    for t in thr:\n",
        "        yhat = (p >= t).astype(int)\n",
        "        tp = int(((yhat == 1) & (y == 1)).sum())\n",
        "        fp = int(((yhat == 1) & (y == 0)).sum())\n",
        "        fn = P - tp\n",
        "        prec = tp / max(tp + fp, 1); rec = tp / max(P, 1)\n",
        "        f1 = 0.0 if prec + rec == 0 else 2 * prec * rec / (prec + rec)\n",
        "        if f1 > best[0]:\n",
        "            best = (f1, float(t), prec, rec)\n",
        "    def patk(k):\n",
        "        idx = np.argsort(-p)[:min(k, len(y))]\n",
        "        return float(np.mean(y[idx])) if len(idx) else np.nan\n",
        "    return {\n",
        "        \"roc_auc\": float(auc), \"pr_auc\": float(pr), \"ks\": ks,\n",
        "        \"logloss\": float(ll), \"brier\": float(br),\n",
        "        \"f1_thr\": best[1], \"f1\": best[0], \"precision\": float(best[2]), \"recall\": float(best[3]),\n",
        "        \"p50\": patk(50), \"p100\": patk(100)\n",
        "    }\n",
        "\n",
        "def compute_business(y, p):\n",
        "    d = g.get(\"business_profit_val\")\n",
        "    if d: return d\n",
        "    # Defaults; change if you used different values in J.5\n",
        "    TP_VALUE, FP_COST, FN_COST, TN_VALUE = 1.0, 0.1, 0.5, 0.0\n",
        "    if y is None or p is None or len(y) != len(p) or len(y) == 0:\n",
        "        return None\n",
        "    thr = np.quantile(p, np.linspace(0, 1, 201))\n",
        "    P = int((y == 1).sum()); N = len(y) - P\n",
        "    best = None\n",
        "    for t in thr:\n",
        "        yhat = (p >= t).astype(int)\n",
        "        TP = int(((yhat == 1) & (y == 1)).sum()); FP = int(((yhat == 1) & (y == 0)).sum())\n",
        "        FN = P - TP; TN = N - FP\n",
        "        prec = TP / max(TP + FP, 1); rec = TP / max(P, 1)\n",
        "        f1 = 0.0 if prec + rec == 0 else 2 * prec * rec / (prec + rec)\n",
        "        profit = TP_VALUE*TP + TN_VALUE*TN - FP_COST*FP - FN_COST*FN\n",
        "        if best is None or profit > best[0]:\n",
        "            best = (profit, float(t), TP, FP, FN, TN, float(prec), float(rec), float(f1))\n",
        "    profit_all_neg = TN_VALUE*N - FN_COST*P\n",
        "    profit_all_pos = TP_VALUE*P - FP_COST*N\n",
        "    return {\n",
        "        \"profit\": float(best[0]), \"threshold\": best[1], \"TP\": best[2], \"FP\": best[3], \"FN\": best[4], \"TN\": best[5],\n",
        "        \"precision\": best[6], \"recall\": best[7], \"f1\": best[8],\n",
        "        \"profit_all_neg\": float(profit_all_neg), \"profit_all_pos\": float(profit_all_pos)\n",
        "    }\n",
        "\n",
        "# Data + features\n",
        "def first_df(names):\n",
        "    for n in names:\n",
        "        obj = g.get(n)\n",
        "        if isinstance(obj, pd.DataFrame): return obj\n",
        "    return None\n",
        "\n",
        "Xref = first_df([\"X_train\",\"X_e3_tr\",\"X_e2_tr\",\"X_e1_tr\"])\n",
        "train_rows = int(Xref.shape[0]) if Xref is not None else None\n",
        "n_features = int(Xref.shape[1]) if Xref is not None else None\n",
        "\n",
        "engineered = []\n",
        "for k in (\"generated_features_f1\",\"generated_features_f2\",\"generated_features_f3\"):\n",
        "    if isinstance(g.get(k), list):\n",
        "        engineered += [x for x in g[k] if isinstance(x, str) and x.strip()]\n",
        "for cand in (\"nz_frac\",\"f_zdist\"):\n",
        "    if Xref is not None and cand in Xref.columns and cand not in engineered:\n",
        "        engineered.append(cand)\n",
        "\n",
        "# Compute\n",
        "y_va, p_va = _to_scores_and_labels()\n",
        "M = compute_metrics(y_va, p_va)\n",
        "B = compute_business(y_va, p_va)\n",
        "\n",
        "# Print report\n",
        "print(\"=== H. Project Outcomes ===\")\n",
        "print(f\"Model: {get_model_name()}\")\n",
        "if train_rows and n_features:\n",
        "    print(f\"Data: rows(train) = {train_rows}, features = {n_features}\")\n",
        "if engineered:\n",
        "    print(\"Engineered features:\", \", \".join(engineered))\n",
        "\n",
        "if M:\n",
        "    print(f\"Technical (VAL): ROC AUC={M['roc_auc']:.6f}, PR AUC={M['pr_auc']:.6f}, KS={M['ks']:.6f}, \"\n",
        "          f\"LogLoss={M['logloss']:.6f}, Brier={M['brier']:.6f}\")\n",
        "    print(f\"Best F1 at {M['f1_thr']:.6f} → P={M['precision']:.3f} R={M['recall']:.3f} F1={M['f1']:.3f} | \"\n",
        "          f\"P@50={M['p50']:.3f}, P@100={M['p100']:.3f}\")\n",
        "else:\n",
        "    print(\"Technical: need y_val and y_score_va (or run J.4) to compute metrics.\")\n",
        "\n",
        "if B:\n",
        "    print(f\"Business: Profit-max threshold={B['threshold']:.6f} → Profit={B['profit']:.2f} \"\n",
        "          f\"(TP/FP/FN/TN={B['TP']}/{B['FP']}/{B['FN']}/{B['TN']}) | \"\n",
        "          f\"Baselines → none={B['profit_all_neg']:.2f}, all={B['profit_all_pos']:.2f}\")\n",
        "else:\n",
        "    print(\"Business: run J.5 (or set TP_VALUE/FP_COST/FN_COST) to compute profit.\")\n"
      ],
      "metadata": {
        "id": "AvFNheh1HtPb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "417d5aa2-8193-4838-b702-04f7cb2b33e1"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== H. Project Outcomes ===\n",
            "Model: HistGradientBoostingClassifier\n",
            "Data: rows(train) = 9455, features = 120\n",
            "Engineered features: f_zdist\n",
            "Technical (VAL): ROC AUC=0.998474, PR AUC=0.858758, KS=0.990192, LogLoss=0.018544, Brier=0.004361\n",
            "Best F1 at 0.762325 → P=0.667 R=0.842 F1=0.744 | P@50=0.380, P@100=0.190\n",
            "Business: Profit-max threshold=0.038551 → Profit=16.10 (TP/FP/FN/TN=19/29/0/2316) | Baselines → none=-9.50, all=-215.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# <Student to fill this section>\n",
        "experiment_results_explanations =\"\"\"\n",
        "auto-pulls your VAL scores & labels, computes and prints technical metrics (ROC/PR AUC, KS, LogLoss, Brier, F1-opt threshold, P@K), and shows business profit at the best threshold (or uses J.5 results if present).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iFF8wsz6HteA"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not modify this code\n",
        "print_tile(size=\"h2\", key='experiment_outcomes_explanations', value=experiment_results_explanations)"
      ],
      "metadata": {
        "id": "WTLHNCXpwhTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "2735903e-98db-4124-940b-30d1bbc431d3"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color:grey\">experiment_outcomes_explanations</p><h2 font-size: 3em>\n",
              "auto-pulls your VAL scores & labels, computes and prints technical metrics (ROC/PR AUC, KS, LogLoss, Brier, F1-opt threshold, P@K), and shows business profit at the best threshold (or uses J.5 results if present).\n",
              "</h2>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thank you"
      ],
      "metadata": {
        "id": "PIpgAu2RwlSt"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}